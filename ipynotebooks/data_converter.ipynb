{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/home/fbuonerba/codes/')\n",
    "from mp_functions import upload_log_return, upload_factor_loadings, request_rates\n",
    "from coinapi_v1 import CoinAPIv1\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import calendar\n",
    "import json\n",
    "import csv\n",
    "\n",
    "datapath='/home/databot/data/coinapi/'\n",
    "homepath='/home/fbuonerba/'\n",
    "\n",
    "ratespath=homepath+'exchange_rates_data/'\n",
    "ohlcvpath=homepath + 'ohlcv_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates=os.listdir(ratespath)\n",
    "\n",
    "ohlcv=os.listdir(ohlcvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non existent data exchange_rate_BTC_BTC_1539525600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1542952800.txt\n",
      "non existent data exchange_rate_BTC_USD_1542970800.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539511200.txt\n",
      "non existent data exchange_rate_LTC_USD_1539554400.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_TRX_USD_1539561600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539457200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1542963600.txt\n",
      "non existent data exchange_rate_DASH_USD_1539561600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1542960000.txt\n",
      "non existent data exchange_rate_BTC_USD_1539583200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539496800.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1539460800.txt\n",
      "non existent data exchange_rate_ADA_USD_1539504000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_ADA_USD_1539590400.txt\n",
      "non existent data exchange_rate_ETC_USD_1539561600.txt\n",
      "non existent data exchange_rate_DASH_USD_1539554400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539601200.txt\n",
      "non existent data exchange_rate_BTC_USD_1539543600.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_XMR_USD_1539561600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539543600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539496800.txt\n",
      "non existent data exchange_rate_LTC_USD_1539597600.txt\n",
      "non existent data exchange_rate_IOTA_USD_1539554400.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539500400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539525600.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_USD_1539478800.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539518400.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539486000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539507600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539460800.txt\n",
      "non existent data exchange_rate_BTC_USD_1542952800.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539558000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1539514800.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539464400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539561600.txt\n",
      "non existent data exchange_rate_XMR_USD_1539554400.txt\n",
      "non existent data exchange_rate_LTC_USD_1539579600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539586800.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539522000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539594000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1542970800.txt\n",
      "non existent data exchange_rate_ADA_USD_1539561600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539468000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539576000.txt\n",
      "non existent data exchange_rate_BTC_USD_1539522000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_USD_1539576000.txt\n",
      "non existent data exchange_rate_BTC_USD_1539540000.txt\n",
      "non existent data exchange_rate_IOTA_USD_1539590400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539572400.txt\n",
      "non existent data exchange_rate_XLM_USD_1539540000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_USD_1539547200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539471600.txt\n",
      "non existent data exchange_rate_ADA_USD_1539554400.txt\n",
      "non existent data exchange_rate_BTC_USD_1542960000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_USD_1539586800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539486000.txt\n",
      "non existent data exchange_rate_BTC_USD_1539482400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539594000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539597600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539500400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539536400.txt\n",
      "non existent data exchange_rate_IOTA_USD_1539561600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539572400.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539547200.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1539532800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539568800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539558000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1542956400.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539568800.txt\n",
      "non existent data exchange_rate_XLM_USD_1539468000.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1539478800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539532800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539514800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539590400.txt\n",
      "non existent data exchange_rate_ADA_USD_1539579600.txt\n",
      "non existent data exchange_rate_LTC_USD_1539590400.txt\n",
      "non existent data exchange_rate_ETC_USD_1539554400.txt\n",
      "non existent data exchange_rate_BTC_USD_1542956400.txt\n",
      "non existent data exchange_rate_NEO_USD_1539554400.txt\n",
      "non existent data exchange_rate_BTC_USD_1542963600.txt\n",
      "non existent data exchange_rate_XLM_USD_1542970800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539464400.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1539536400.txt\n",
      "non existent data exchange_rate_XLM_USD_1539597600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539468000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539583200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539601200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539504000.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539579600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539554400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539554400.txt\n",
      "non existent data exchange_rate_XLM_USD_1539457200.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_USD_1539597600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539550800.txt\n",
      "non existent data exchange_rate_BTC_USD_1539579600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539565200.txt\n",
      "non existent data exchange_rate_BTC_USD_1539518400.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_LTC_USD_1539561600.txt\n",
      "non existent data exchange_rate_XEM_USD_1539554400.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_USD_1539475200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539482400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539493200.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539489600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539493200.txt\n",
      "non existent data exchange_rate_BTC_USD_1539511200.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_BTC_BTC_1539550800.txt\n",
      "non existent data exchange_rate_XLM_USD_1539579600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539504000.txt\n",
      "non existent data exchange_rate_BTC_USD_1539471600.txt\n",
      "non existent data exchange_rate_TRX_USD_1539590400.txt\n",
      "non existent data exchange_rate_BTC_USD_1539529200.txt\n",
      "non existent data exchange_rate_BTC_USD_1539457200.txt\n",
      "non existent data exchange_rate_LTC_USD_1539471600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539540000.txt\n",
      "non existent data exchange_rate_BTC_USD_1539507600.txt\n",
      "non existent data exchange_rate_BTC_USD_1539489600.txt\n",
      "non existent data exchange_rate_BTC_BTC_1539565200.txt\n",
      "golaso!\n",
      "non existent data exchange_rate_TRX_USD_1539554400.txt\n"
     ]
    }
   ],
   "source": [
    "########TRANSFORM RATES############\n",
    "D={}\n",
    "counter=0\n",
    "for x in rates:\n",
    "    counter+=1\n",
    "    if counter % 100000 ==0:\n",
    "        print('golaso!')\n",
    "    with open(ratespath + x) as infile:\n",
    "        try:\n",
    "            y=json.load(infile)\n",
    "            if y!={} and y!='{}':\n",
    "                ytime=y['time'][:10].replace('-','')\n",
    "                if ytime not in D.keys():\n",
    "                    D[ytime]=[]\n",
    "                D[ytime].append(y)\n",
    "        except:\n",
    "            print('non existent data', x)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=list(D.keys())\n",
    "names=['time', 'rate', 'asset_id_base', 'asset_id_quote']\n",
    "for w in days:\n",
    "    with open(datapath + w[:4]+'/'+w[4:6]+'/'+w[6:]+'/'+w+'.rates','w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=names)\n",
    "        writer.writeheader()\n",
    "        for symbol in D[w]:\n",
    "            writer.writerow(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "600000\n",
      "650000\n",
      "700000\n",
      "750000\n",
      "800000\n",
      "815942\n"
     ]
    }
   ],
   "source": [
    "###########TRANSFORM OHLCV#############\n",
    "E={}\n",
    "counter=0\n",
    "for x in ohlcv:\n",
    "    X=x.split('_')\n",
    "    exchange=X[1]\n",
    "    base=X[3]\n",
    "    quote=X[4]\n",
    "    if base=='SPOT':\n",
    "        base=X[4]\n",
    "        quote=X[2]\n",
    "    counter+=1\n",
    "    if counter % 50000 ==0:\n",
    "        print(counter)\n",
    "    with open(ohlcvpath + x) as infile:\n",
    "        try:\n",
    "            y=json.load(infile)\n",
    "            if y!=[] and y!='[]':\n",
    "                ytime=y['time_period_start'][:10].replace('-','')\n",
    "                if ytime not in E.keys():\n",
    "                    E[ytime]=[]\n",
    "                y['exchange']=exchange\n",
    "                y['asset_id_base']=base\n",
    "                y['asset_id_quote']=quote\n",
    "                if base=='SPOT' or quote=='SPOT' or exchange=='SPOT':\n",
    "                    print(base, quote, exchange)\n",
    "                E[ytime].append(y)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(counter)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=list(E.keys())\n",
    "names=[\"time_close\",\"time_open\",\"price_close\",\"price_open\", 'asset_id_base','asset_id_quote','exchange',\"trades_count\",\"volume_traded\", \"price_high\", \"price_low\",\"time_period_start\",\"time_period_end\"] \n",
    "for w in days:\n",
    "    with open(datapath + w[:4]+'/'+w[4:6]+'/'+w[6:]+'/'+w+'.ohlcv','w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=names)\n",
    "        writer.writeheader()\n",
    "        for symbol in E[w]:\n",
    "            writer.writerow(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "returnspath=homepath + 'log_returns_data/'\n",
    "\n",
    "returns=os.listdir(returnspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "600000\n",
      "650000\n",
      "700000\n",
      "750000\n",
      "800000\n",
      "850000\n",
      "900000\n",
      "950000\n",
      "1000000\n",
      "1050000\n",
      "1100000\n",
      "1150000\n",
      "1200000\n",
      "1250000\n",
      "1300000\n",
      "1301384\n"
     ]
    }
   ],
   "source": [
    "###############TRANSFORM RETURNS##############\n",
    "F={}\n",
    "counter=0\n",
    "for x in returns:\n",
    "    x_temp=x[:-4]\n",
    "    X=x_temp.split('_')\n",
    "    base=X[2]\n",
    "    quote=X[3]\n",
    "    time_begin=datetime.utcfromtimestamp(float(X[4])).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    time_end=datetime.utcfromtimestamp(float(X[5])).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    tim=datetime.utcfromtimestamp(float(X[5])).strftime('%Y%m%d')\n",
    "    if tim not in F.keys():\n",
    "        F[tim]=[]\n",
    "    counter+=1\n",
    "    if counter % 50000 ==0:\n",
    "        print(counter)\n",
    "    with open(returnspath + x) as infile:\n",
    "        try:\n",
    "            Y=json.load(infile)\n",
    "            y={}\n",
    "            y['time_start']=time_begin\n",
    "            y['time_end']=time_end\n",
    "            y['asset_id_base']=base\n",
    "            y['asset_id_quote']=quote\n",
    "            y['log_return']=Y\n",
    "            F[tim].append(y)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(counter)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19700101 [{'asset_id_quote': 'BTC', 'log_return': nan, 'asset_id_base': 'USD', 'time_end': '1970-01-01T00:03:20', 'time_start': '1970-01-01T00:01:40'}]\n",
      "19700102 [{'asset_id_quote': 'BTC', 'log_return': nan, 'asset_id_base': 'BTC', 'time_end': '1970-01-02T00:00:00', 'time_start': '1970-01-01T00:00:00'}]\n"
     ]
    }
   ],
   "source": [
    "days=list(F.keys())\n",
    "names=['time_start', 'time_end', 'asset_id_base', 'asset_id_quote', 'log_return']\n",
    "for w in days:\n",
    "    try:\n",
    "        with open(datapath + w[:4]+'/'+w[4:6]+'/'+w[6:]+'/'+w+'.log_returns','w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=names)\n",
    "            writer.writeheader()\n",
    "            for symbol in F[w]:\n",
    "                writer.writerow(symbol)\n",
    "    except:\n",
    "        print(w, F[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########TRANSFORM CMC DAILY DATA################\n",
    "G={}\n",
    "cmcpath=homepath + 'cmc_data/'\n",
    "cmc=os.listdir(cmcpath)\n",
    "cmc1=[x for x in cmc if ('hist' not in x)]\n",
    "\n",
    "for x in cmc1:\n",
    "    date = datetime.utcfromtimestamp(float(x[-14:-4])).strftime('%Y%m%d')\n",
    "    if date not in G.keys():\n",
    "        G[date]=[]\n",
    "    with open(cmcpath + x) as infile:\n",
    "        j=json.load(infile)\n",
    "    G[date].append(j)\n",
    "keys=list(G[date][0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=G.keys()\n",
    "for d in days:\n",
    "    with open(datapath+d[:4]+'/'+d[4:6]+'/'+d[6:]+'/'+d+'.cmc_daily','w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for x in G[d]:\n",
    "            try:\n",
    "                writer.writerow(x)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########TRANSFORM CMC HISTORICAL DATA################\n",
    "H={}\n",
    "\n",
    "cmc2=[x for x in cmc if ('hist' in x)]\n",
    "for x in cmc2:\n",
    "    date = datetime.utcfromtimestamp(float(x[-14:-4])).strftime('%Y%m%d')\n",
    "    if date not in H.keys():\n",
    "        H[date]=[]\n",
    "    with open(cmcpath + x) as infile:\n",
    "        j=json.load(infile)\n",
    "    H[date].append(j)\n",
    "keys1=list(H[date][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=H.keys()\n",
    "for d in days:\n",
    "    with open(datapath+d[:4]+'/'+d[4:6]+'/'+d[6:]+'/'+d+'.cmc_historical','w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=keys1)\n",
    "        writer.writeheader()\n",
    "        for x in H[d]:\n",
    "            try:\n",
    "                writer.writerow(x)\n",
    "            except:\n",
    "                print(d, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############COMPUTE DAILY VOLUMES###############\n",
    "for root, dirs, files in os.walk(datapath, topdown=False):\n",
    "    for randomfile in files:\n",
    "        randomfile=os.path.join(root, randomfile)\n",
    "        if 'ohlcv' in randomfile:\n",
    "            volume={}\n",
    "            with open(randomfile, 'r') as csvfile:\n",
    "                sbam = csv.DictReader(csvfile)\n",
    "                for row in sbam:\n",
    "                    rowsym=row['asset_id_base']+'_'+row['asset_id_quote']\n",
    "                    if 'SPOT' in rowsym:\n",
    "                        print(randomfile)\n",
    "                    if rowsym not in volume.keys():\n",
    "                        volume[rowsym]={}\n",
    "                        volume[rowsym]['time_period_start']=row['time_period_start']\n",
    "                        volume[rowsym]['time_period_end']=row['time_period_end']\n",
    "                        volume[rowsym]['asset_id_base']=row['asset_id_base']\n",
    "                        volume[rowsym]['asset_id_quote']=row['asset_id_quote']\n",
    "                        volume[rowsym]['volume_traded']=0\n",
    "                    volume[rowsym]['volume_traded']+=float(row['volume_traded'])\n",
    "            names=['time_period_start','time_period_end','asset_id_base','asset_id_quote','volume_traded']\n",
    "            pairs=list(volume.keys())\n",
    "            with open(randomfile[:-5]+'volumes','w') as outfile:\n",
    "                #print(randomfile[:-5]+'volumes')\n",
    "                writer = csv.DictWriter(outfile, fieldnames=names)\n",
    "                writer.writeheader()\n",
    "                for w in pairs:\n",
    "                    writer.writerow(volume[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
