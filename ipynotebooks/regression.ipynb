{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/home/fbuonerba/codes/')\n",
    "from mp_functions import upload_log_return, upload_factor_loadings\n",
    "from coinapi_v1 import CoinAPIv1\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import calendar\n",
    "import json\n",
    "import urllib.request\n",
    "import multiprocessing as mp\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/fbuonerba/codes/meta_data/new_coins.txt') as ff:\n",
    "    coins=json.load(ff)\n",
    "coins=np.array(coins)\n",
    "quotes=['USD','BTC']\n",
    "#sysm=[str(coin)+'_'+str(quote) for coin in coins for quote in quotes]\n",
    "def get_returns(beg,end):\n",
    "    #weights=0 or 1\n",
    "    t=beg\n",
    "    matrix=[]\n",
    "    while t<=end+1:\n",
    "        ret_t=[]\n",
    "        for base in coins:\n",
    "            for quote in quotes:\n",
    "                returns=upload_log_return(t, base, quote, 86400)\n",
    "                if np.isnan(returns)==True:\n",
    "                    returns=0\n",
    "                ret_t.append(returns)\n",
    "                #print(base,quote)\n",
    "        matrix.append(ret_t)\n",
    "        t+=86400\n",
    "    R=np.array(matrix)\n",
    "    norms=np.linalg.norm(R, axis=0)\n",
    "    W=np.where(norms==0)\n",
    "    R=np.delete(R, W, axis=1) \n",
    "    std=np.std(R, axis=0)\n",
    "    #return degenerate_indices, returns\n",
    "    return(W, R)\n",
    "\n",
    "#####W[0]=those pairs for which no trading activity is recorded\n",
    "#VET,NPXS have no data for this time period. Indeed they were ranked low on cmc.\n",
    "#then BTC has no data vs BTC, the rest have no data vs USD.\n",
    "# ind_usd=np.array([int(x/2) for x in W[0] if x%2==0])\n",
    "# ind_btc=np.array([int(x/2) for x in W[0] if x%2==1])\n",
    "# bad_coins_usd=coins[ind_usd]\n",
    "# bad_coins_btc=coins[ind_btc]\n",
    "# very_bad_coins=[x for x in bad_coins_usd if x in bad_coins_btc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Factors: January to April#####\n",
    "#####log_mkcap and coin_ratio computed averaging.\n",
    "#####Those are the good ones!\n",
    "factors=[]\n",
    "keys=['returns_variance', 'returns_strength', 'rates_high_low','turnover', 'log_marketcap','coin_ratio']\n",
    "folder='/home/fbuonerba/factor_loadings/factors_'\n",
    "\n",
    "def get_raw_factors(beg,end,W):\n",
    "    factors=[]\n",
    "    std=[]\n",
    "    for coin in coins:\n",
    "        for quote in quotes:\n",
    "            with open(folder+coin+'_'+quote+'_'+str(beg)+'_'+str(end)+'_86400.txt') as data:\n",
    "                fac=json.load(data)\n",
    "            ordr=[]\n",
    "            for key in keys:\n",
    "                if key=='returns_variance':\n",
    "                    E=fac[key]**.5\n",
    "                    std.append(E)\n",
    "                else:\n",
    "                    E=fac[key]\n",
    "                ordr.append(E)\n",
    "            factors.append(ordr)\n",
    "            #factors.append(fac)\n",
    "    factors=np.array(factors)\n",
    "    std=np.array(std)\n",
    "    factors=np.delete(factors, W, axis=0)\n",
    "    std=np.delete(std, W, axis=0)\n",
    "    std=std.reshape(-1,1)\n",
    "    #####here we do normalization using z-score along coin axis#####\n",
    "    factors[np.where(np.isnan(factors)==True)]=0\n",
    "    \n",
    "    ###There are two NaN entries, corresponding to coin ratio of BCD, 43rd position.\n",
    "    ###In a random cmc_historical, the supply is nan. Confirmed on cmc website chart:\n",
    "    #at the time BCD was doing poorly - in march it was ranked 1250th.\n",
    "    return(std, factors)\n",
    "\n",
    "def get_processed_factors(beg,end,W):\n",
    "    std, factors=get_raw_factors(beg,end,W)\n",
    "    factors=(factors-np.mean(factors,axis=0))/np.var(factors,axis=0)**.5\n",
    "    return(std, factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Factors: January to April#####\n",
    "#####log_mkcap and coin_ratio computed on the day.\n",
    "factors=[]\n",
    "keys=['returns_variance', 'returns_strength', 'rates_high_low','turnover']\n",
    "exact_keys=['log_mkcap_exact_','coin_ratio_exact_']\n",
    "folder='/home/fbuonerba/factor_loadings/factors_'\n",
    "exact_folder='/home/fbuonerba/factor_loadings/'\n",
    "def get_raw_barra_factors(beg,end,W):\n",
    "    factors=[]\n",
    "    std=[]\n",
    "    for coin in coins:\n",
    "        for quote in quotes:\n",
    "            with open(folder+coin+'_'+quote+'_'+str(beg)+'_'+str(end)+'_86400.txt') as data:\n",
    "                fac=json.load(data)\n",
    "            ordr=[]\n",
    "            for key in keys:\n",
    "                if key=='returns_variance':\n",
    "                    E=fac[key]**.5\n",
    "                    std.append(E)\n",
    "                else:\n",
    "                    E=fac[key]\n",
    "                ordr.append(E)\n",
    "            ####exact factors####\n",
    "            with open(exact_folder+exact_keys[0]+coin+'_'+quote+'_'+str(end)+'.txt') as ff:\n",
    "                exc=json.load(ff)\n",
    "            ordr.append(exc)\n",
    "            with open(exact_folder+exact_keys[1]+coin+'_'+str(end)+'.txt') as ff:\n",
    "                exc=json.load(ff)\n",
    "            ordr.append(exc)\n",
    "            factors.append(ordr)\n",
    "    actors=np.array(factors)\n",
    "    std=np.array(std)\n",
    "    factors=np.delete(factors, W, axis=0)\n",
    "    std=np.delete(std, W, axis=0)\n",
    "    std=std.reshape(-1,1)\n",
    "    factors[np.where(np.isnan(factors)==True)]=0\n",
    "    return(std, factors)\n",
    "    ###There are two NaN entries, corresponding to coin ratio of BCD, 43rd position.\n",
    "    ###In a random cmc_historical, the supply is nan. Confirmed on cmc website chart:\n",
    "    #at the time BCD was doing poorly - in march it was ranked 1250th.\n",
    "def get_processed_barra_factors(beg,end,W):\n",
    "    std, factors=get_raw_barra_factors(beg,end,W)\n",
    "    factors=(factors-np.mean(factors,axis=0))/np.var(factors,axis=0)**.5\n",
    "    return(std, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "####regression against returns from April 2nd to May 2nd; loadings computed on April 1st.####\n",
    "def get_stats(beg,end,beg1,end1,method, weight):\n",
    "    #method=averaged or barra\n",
    "    #weight=0 or 1\n",
    "    W,R=get_returns(beg,end)\n",
    "    if method=='averaged':\n",
    "        std, factors=get_processed_factors(beg1,end1,W)\n",
    "        if weight==0:\n",
    "            pass\n",
    "        else:\n",
    "            factors=factors*(std**-1)\n",
    "    elif method=='barra':\n",
    "        std, factors=get_processed_barra_factors(beg1,end1,W)\n",
    "        if weight==0:\n",
    "            pass\n",
    "        else:\n",
    "            factors=factors*(std**-1)\n",
    "    reg=linear_model.LinearRegression()\n",
    "    #sklearn automatically preprocesses the data by removing np.mean(axis=0)#\n",
    "    reg.fit(factors,R.T)\n",
    "    beta=reg.coef_\n",
    "    inter=reg.intercept_\n",
    "    inter=inter.reshape(-1,1)\n",
    "    total_beta=np.hstack((beta,inter)) \n",
    "    total_factors=np.hstack((factors, np.ones(factors.shape[0]).reshape(-1,1)))\n",
    "    R_hat=reg.predict(factors) #predicted returns = (tot_fact).(tot_beta.T)\n",
    "    #####compute r_squared and F_scores#####\n",
    "    #numpy and sklearn have built-in functions computing r2.\n",
    "    #reg.score computes the mean along axis=0\n",
    "    #r2_score computes the mean over full matrix. Example:\n",
    "    #r2_score(R.T,R_hat1,multioutput='variance_weighted')\n",
    "    residuals=R.T-R_hat\n",
    "    R_mean=np.mean(R.T,axis=0) #daily average return\n",
    "    tss=np.sum( (R.T-R_mean)**2, axis=0 ) #daily total_sum_squares\n",
    "    rss=np.sum( (R.T-R_hat)**2, axis=0 ) #daily residual_sum_squares ~ var residuals\n",
    "    r2=1-rss/tss #daily R^2\n",
    "    cov_residuals=np.dot(residuals.T,residuals)/(factors.shape[0]-factors.shape[1])#daily\n",
    "    var_residuals=cov_residuals.diagonal() #daily unbiased variance of residuals\n",
    "    F=((tss-rss)/factors.shape[1])/var_residuals #daily F-scores\n",
    "    #####compute z_scores, using total_beta and total_factors for compactness#####\n",
    "    inv=np.linalg.inv(np.dot(total_factors.T,total_factors)) #usual (X^T.X)^{-1}\n",
    "    cov_beta=np.tensordot(inv,var_residuals, axes=0) #daily covariance of betas: inv*var(residual)\n",
    "    var_beta=cov_beta.diagonal() #daily variance of betas\n",
    "    std_beta=np.sqrt(var_beta) #daily standard errors\n",
    "    z_scores=total_beta/std_beta\n",
    "    return(total_beta, total_factors, R_hat, r2, F, z_scores)\n",
    "    \n",
    "# df_list=[]\n",
    "# for t in range(30):\n",
    "#     df=pd.DataFrame()\n",
    "#     df1=pd.DataFrame()\n",
    "#     df['factor_name']=['returns_variance', 'returns_strength', 'returns_high_low', 'turnover', 'average_log_mkcap', 'average_coin_ratio','1']\n",
    "#     df['beta']=total_beta[t]\n",
    "#     df['std_error']=std_beta[t]\n",
    "#     df['z_score']=z_scores[t]\n",
    "#     df1['r_squared']=np.array([r2[t]])\n",
    "#     df1['F_score']=np.array([F[t]])\n",
    "#     df_list.append([df,df1])\n",
    "# r2_barra_wt=r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaged10 [0.21910224 0.21843303 0.1719067  0.19680271 0.19798863 0.17341126\n",
      " 0.09337745]\n",
      "barra10 [0.23464047 0.25262882 0.19286133 0.21248771 0.20915593 0.19243795\n",
      " 0.11491211]\n",
      "barra00 [0.77553548 0.56876826 0.2654341  0.66683001 0.71535337 0.42790842\n",
      " 0.09352656]\n",
      "averaged00 [0.76149581 0.54469087 0.22337914 0.65219095 0.70271566 0.39468982\n",
      " 0.05424383]\n",
      "*******************\n",
      "averaged01 [0.86266332 0.1007106  0.79798622 0.05906898 0.22335251 0.03211415\n",
      " 0.23419538]\n",
      "barra11 [0.29160276 0.07003139 0.18620155 0.029991   0.14858962 0.03582689\n",
      " 0.12926576]\n",
      "averaged11 [0.29020461 0.05527754 0.18160981 0.02219976 0.11216792 0.02304809\n",
      " 0.12627529]\n",
      "barra01 [0.86272134 0.13748312 0.8027595  0.06507402 0.26692414 0.04117157\n",
      " 0.23486581]\n",
      "*******************\n",
      "averaged02 [0.11002444 0.48603144 0.5877402  0.11168411 0.56862633 0.42895364\n",
      " 0.05912551]\n",
      "barra02 [0.1354339  0.5168336  0.60562253 0.19247145 0.59909818 0.45504422\n",
      " 0.06939645]\n",
      "barra12 [0.22086513 0.14108849 0.14909606 0.14959044 0.29453871 0.07153311\n",
      " 0.09338614]\n",
      "averaged12 [0.14540668 0.1157459  0.14284258 0.10224597 0.27213826 0.04776174\n",
      " 0.07900308]\n",
      "*******************\n",
      "averaged03 [0.00873378 0.78795596 0.15193175 0.49999496 0.13441496 0.2379579\n",
      " 0.05491672]\n",
      "barra03 [0.04944548 0.78886522 0.28723408 0.51107295 0.14977473 0.27723222\n",
      " 0.0664163 ]\n",
      "barra13 [0.05236361 0.31998109 0.27540077 0.26893756 0.12589491 0.18615478\n",
      " 0.04106057]\n",
      "averaged13 [0.0270042  0.31723849 0.18451308 0.26709392 0.11973691 0.15601773\n",
      " 0.03624192]\n",
      "[2 2 2 2 2 2 1]\n",
      "[3 3 3 3 3 3 3]\n",
      "[2 1 1 1 1 1 2]\n",
      "[2 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "methods=['averaged','barra']\n",
    "weights=[0,1]\n",
    "T=[0,1,2,3]\n",
    "beg=[1522540800+3600+t*604800 for t in T]\n",
    "end=[1522540800+(t+1)*604800 for t in T]\n",
    "beg1=[1515283200+t*604800 for t in T]\n",
    "end1=[1522540800+t*604800 for t in T]\n",
    "DDD={}\n",
    "\n",
    "for m in methods:\n",
    "    for w in weights:\n",
    "        for t in T:\n",
    "            roar=str(m)+str(w)+str(t)\n",
    "            DDD[roar]=[get_stats(beg[t],end[t],beg1[t],end1[t],m,w)]\n",
    "\n",
    "\n",
    "ralf0=np.empty((7,))\n",
    "ralf1=np.empty((7,))\n",
    "ralf2=np.empty((7,))\n",
    "ralf3=np.empty((7,))\n",
    "\n",
    "for key in DDD.keys():\n",
    "    if key[-1]=='0':\n",
    "        ralf0=np.vstack((ralf0, DDD[key][0][3]))\n",
    "        print(key,DDD[key][0][3])\n",
    "ralf0=ralf0[1:]\n",
    "print('*******************')\n",
    "for key in DDD.keys():\n",
    "    if key[-1]=='1':\n",
    "        ralf1=np.vstack((ralf1, DDD[key][0][3]))\n",
    "        print(key,DDD[key][0][3])\n",
    "ralf1=ralf1[1:]\n",
    "print('*******************')\n",
    "for key in DDD.keys():\n",
    "    if key[-1]=='2':\n",
    "        ralf2=np.vstack((ralf2, DDD[key][0][3]))\n",
    "        print(key,DDD[key][0][3])\n",
    "ralf2=ralf2[1:]\n",
    "print('*******************')\n",
    "for key in DDD.keys():\n",
    "    if key[-1]=='3':\n",
    "        ralf3=np.vstack((ralf3, DDD[key][0][3]))\n",
    "        print(key,DDD[key][0][3])\n",
    "ralf3=ralf3[1:]\n",
    "\n",
    "totralf=[ralf0,ralf1,ralf2,ralf3]\n",
    "\n",
    "for i in range(4):\n",
    "    win=np.argmax(totralf[i], axis=0)\n",
    "    print(win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare R^2-performance of barra/averaged factors, weighted/non weighted regressions.\n",
    "\n",
    "print(r2_mine_nowt)\n",
    "print(r2_mine_wt)\n",
    "print(r2_barra_nowt)\n",
    "print(r2_barra_wt)\n",
    "\n",
    "t=list(range(31))\n",
    "fig = plt.figure(figsize=(13, 13))\n",
    "plt.title('R^2 comparison')\n",
    "plt.scatter(t, r2_mine_nowt, c='r', label='mine')\n",
    "plt.scatter(t, r2_mine_wt, c='b', label='mine_weight')\n",
    "plt.scatter(t, r2_barra_nowt, c='g', label='barra')\n",
    "plt.scatter(t, r2_barra_wt, c='y', label='barra_weight')\n",
    "plt.legend()\n",
    "plt.savefig('R^2_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "FF=np.vstack((r2_mine_nowt,r2_mine_wt,r2_barra_nowt,r2_barra_wt))\n",
    "scores=np.argmax(FF,axis=0)\n",
    "print(variances)\n",
    "[len(np.where(scores==i)[0]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###compute covariance of factor returns###\n",
    "#either compute cov of total_beta; or compute cov of beta, and attach a 1x1 block with inter.\n",
    "#results are slightly different - intercept and beta are slightly correlated over time.\n",
    "ess_cov=np.cov(beta.T)\n",
    "ess1=np.hstack((ess_cov, np.zeros(6).reshape(-1,1)))\n",
    "ess2=np.vstack((ess1, np.zeros(7).reshape(1,-1)))\n",
    "ess2[-1,-1]=np.var(inter)\n",
    "\n",
    "ess_totcov=np.cov(total_beta.T)\n",
    "totfac=np.hstack((np.ones((factors.shape[0], 1)), factors))\n",
    "D=np.cov(residuals, bias=1)\n",
    "D1=np.var(residuals,axis=1)\n",
    "D2=D.diagonal()\n",
    "\n",
    "COV=np.dot(totfac, np.dot(ess_totcov,totfac.T)) + np.diag(D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###compute weights of optimal portfolio, given alpha###\n",
    "#ideally alpha=returns, which you don't know.\n",
    "#Namely, minimize w^T.C.w-alpha.w \n",
    "#solution is w=C^{-1}.alpha\n",
    "def optimal_weights(alpha):\n",
    "    #alpha=np.random.rand(factors.shape[0], 1)\n",
    "    COV_=np.linalg.inv(COV)\n",
    "    return np.dot(COV_,alpha)\n",
    "#computeoptimal portfolio return: take returns after May2nd and check performance.\n",
    "def portfolio_return(alpha, days_after_may2=1):\n",
    "    test_returns=[]\n",
    "    for base in coins:\n",
    "        for quote in quotes:\n",
    "            returns=upload_log_return(1525219200+days_after_may2*86400, base, quote, 86400)\n",
    "            if np.isnan(returns)==True:\n",
    "                returns=0\n",
    "            test_returns.append(returns)\n",
    "    test_returns=np.delete(test_returns, W)\n",
    "    print(test_returns)\n",
    "    ignorant_returns=np.dot(alpha,test_returns)\n",
    "    hedged_returns=np.dot(optimal_weights(alpha).T, test_returns)\n",
    "    return ignorant_returns, hedged_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=np.zeros(76) \n",
    "alpha[6:]=1\n",
    "print(alpha)\n",
    "alpha/=np.sum(alpha)\n",
    "#optimal_weights(alpha)\n",
    "print(portfolio_return(alpha, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###looking for homoscedasticity: variance of errors independent of time/estimated returns:\n",
    "####white test for homoscedasticity: regress squared-error against regressors, check r2.\n",
    "resi=residuals**2\n",
    "reg.fit(factors, resi)\n",
    "residuals_hat=reg.predict(factors)\n",
    "resmean=np.mean(resi,axis=0) #daily average return\n",
    "tss=np.sum( (resi-resmean)**2, axis=0 ) #daily total_sum_squares\n",
    "rss=np.sum( (resi- residuals_hat)**2, axis=0 ) #daily residual_sum_squares ~ var residuals\n",
    "r2=1-rss/tss #daily R^2\n",
    "\n",
    "#compute covariance of error timeseries: TT_t,s=cov(err_t,err_s).\n",
    "#TT should be close to a homothety\n",
    "TT=np.cov(residuals.T)\n",
    "TTD=TT.diagonal()\n",
    "plt.scatter(range(len(TTD)),TTD)\n",
    "#on each row, pick column with maximal entry and check if it's diagonal.\n",
    "#works beautifully, T is almost diagonal\n",
    "MAX=np.argmax(TT,axis=0)\n",
    "MAX-list(range(len(TT)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####looking for patterns in variance of returns versus marketcap.\n",
    "\n",
    "pathh='/home/fbuonerba/factor_loadings/'\n",
    "mkcap_list_usd=[]\n",
    "mkcap_list_btc=[]\n",
    "variance_usd=[]\n",
    "variance_btc=[]\n",
    "for coin in coins:\n",
    "    with open(pathh+'log_mkcap_exact_'+str(coin)+'_USD_1531612800.txt')as uo:\n",
    "        mcap=json.load(uo)\n",
    "    mkcap_list_usd.append(mcap)\n",
    "    with open(pathh+'log_mkcap_exact_'+str(coin)+'_BTC_1531612800.txt')as uoo:\n",
    "        cap=json.load(uoo)\n",
    "    mkcap_list_btc.append(cap)\n",
    "    with open(pathh+'variance_'+str(coin)+'_USD_1524355200_1531612800_604800.txt')as uo:\n",
    "        var=json.load(uo)\n",
    "    variance_usd.append(var)\n",
    "    with open(pathh+'variance_'+str(coin)+'_BTC_1524355200_1531612800_604800.txt')as uoo:\n",
    "        varr=json.load(uoo)\n",
    "    variance_btc.append(varr)\n",
    "\n",
    "order_usd=np.argsort(np.array(mkcap_list_usd))\n",
    "order_btc=np.argsort(np.array(mkcap_list_btc))\n",
    "new_var_usd=[variance_usd[x] for x in order_usd]\n",
    "new_var_btc=[variance_btc[x] for x in order_btc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####Outliers = HB,DIG,ODE for both USD and BTC.\n",
    "plt.scatter(list(range(len(new_var_btc))), new_var_btc, c='r', label='btc')\n",
    "plt.savefig('ordered_var_btc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(list(range(len(new_var_usd))), new_var_usd, c='b', label='usd')\n",
    "plt.savefig('ordered_var_usd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report printout\n",
    "print('Definition of factors, for each coin pair:')\n",
    "print('*returns_variance = var(returns_t), over weekly returns Jan 7th-Apr 1st.')\n",
    "print('*returns_strength=sum_t( log(1+return_t) ) over returns as above.')\n",
    "print('*returns_high_low=log( max_t(return_t)/min_t(return_t) ) over returns as above.')\n",
    "print('*turnover=(total traded volume)/(average coin supply) over trades Jan 7th-Apr 1st.')\n",
    "print('*log_mkcap=average_t( log(coin_supply_t*price_t) ) over weekly supply and price Jan 7th-Apr 1st.')\n",
    "print('*coin_ratio=average_t(coin_supply_t/coin_supply_ever) over weekly supply as above.')\n",
    "print('Factor loadings have been scaled by z-score.')\n",
    "print('')\n",
    "for y in df_list:    \n",
    "    for x in y:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####regression against returns on April 1st only#####\n",
    "t=1522540800\n",
    "ret=[]\n",
    "for base in coins:\n",
    "    for quote in quotes:\n",
    "        returns=upload_log_return(t, base, quote, 86400)\n",
    "        if np.isnan(returns)==True:\n",
    "            returns=0\n",
    "        ret.append(returns)\n",
    "ret=np.array(ret)\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(factors,ret.T)\n",
    "beta=reg.coef_\n",
    "inter=reg.intercept_\n",
    "ret_hat=reg.predict(factors)\n",
    "rss=np.linalg.norm(ret-ret_hat)**2\n",
    "var_error=rss/(factors.shape[0]-factors.shape[1])\n",
    "tss=np.linalg.norm(ret-np.mean(ret))**2\n",
    "r_square=1-rss/tss\n",
    "F_score=(tss-rss)/(factors.shape[1]*var_error)\n",
    "cov_beta=np.linalg.inv(np.dot(factors.T,factors))*var_error\n",
    "std_errors=np.sqrt(cov_beta.diagonal())\n",
    "t_stats=beta/std_errors\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['factor_name']=['returns_variance', 'returns_strength', 'returns_high_low', 'turnover', 'log_mkcap', 'coin_ratio']\n",
    "df['beta']=beta\n",
    "df['std_error']=std_errors\n",
    "df['z_score']=t_stats\n",
    "df1=pd.DataFrame()\n",
    "df1['r_squared']=np.array([r_square])\n",
    "df1['F_score']=np.array([F_score])\n",
    "print('Regression on April 1st returns.')\n",
    "print('Definition of factors, for each coin pair:')\n",
    "print('*returns_variance = var(returns_t), over weekly returns Jan 7th-Apr 1st.')\n",
    "print('*returns_strength=sum_t( log(1+return_t) ) over returns as above.')\n",
    "print('*returns_high_low=log( max_t(return_t)/min_t(return_t) ) over returns as above.')\n",
    "print('*turnover=(total traded volume)/(average coin supply) over trades Jan 7th-Apr 1st.')\n",
    "print('*log_mkcap=average_t( log(coin_supply_t*price_t) ) over weekly supply and price Jan 7th-Apr 1st.')\n",
    "print('*coin_ratio=average_t(coin_supply_t/coin_supply_ever) over weekly supply as above.')\n",
    "print('Factor loadings have been scaled by z-score.')\n",
    "print('')\n",
    "print(df)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####February to May#####\n",
    "\n",
    "from mp_functions import upload_log_return\n",
    "with open('/home/fbuonerba/codes/meta_data/top_coins.txt') as ff:\n",
    "    coins=json.load(ff)\n",
    "coins=list(coins)\n",
    "####LIZA is outlier for 2 of the risk factors...####\n",
    "coins.remove('LIZA')\n",
    "quotes=['USD','BTC']\n",
    "#sysm=[str(coin)+'_'+str(quote) for coin in coins for quote in quotes]\n",
    "t=1517702400\n",
    "matrix=[]\n",
    "#matrix of daily log_returns (time, base_quote)\n",
    "while t<=1525564801:\n",
    "    ret_t=[]\n",
    "    for base in coins:\n",
    "        for quote in quotes:\n",
    "            returns=upload_log_return(t, base, quote, 86400)\n",
    "            if np.isnan(returns)==True:\n",
    "                returns=0\n",
    "            ret_t.append(returns)\n",
    "            #print(base,quote)\n",
    "    matrix.append(ret_t)\n",
    "    t+=86400\n",
    "R=np.array(matrix)\n",
    "\n",
    "factors=[]\n",
    "factor_names1=['variance_', 'strength_', 'high_low_']\n",
    "factor_names2=['turnover_', 'log_mkcap_']\n",
    "factor_names3=['coin_ratio_']\n",
    "path='/home/fbuonerba/codes/factor_loadings/'\n",
    "finpath1='_'+str(1517702400)+'_'+str(1525564800)+'_'+str(604800)+'.txt'\n",
    "finpath2='_'+str(1517702400)+'_'+str(1525564800)+'.txt'\n",
    "finpath3='.txt'\n",
    "for base in coins:\n",
    "    for quote in quotes:\n",
    "        sym=str(base)+'_'+str(quote)\n",
    "        sym_row=[]\n",
    "        for name in factor_names1:\n",
    "            with open(path+name+sym+finpath1) as file:\n",
    "                x=json.load(file)\n",
    "            sym_row.append(x)\n",
    "        for name in factor_names2:\n",
    "            with open(path+name+sym+finpath2) as file:\n",
    "                x=json.load(file)\n",
    "            sym_row.append(x)\n",
    "        for name in factor_names3:\n",
    "            #symll=sym.split('_')\n",
    "            with open(path+name+base+finpath3) as file:\n",
    "                x=json.load(file)\n",
    "            sym_row.append(x)\n",
    "        #sym_row.append(1)\n",
    "        factors.append(sym_row)\n",
    "factors=np.array(factors)  \n",
    "#normalization using z-score along coin axis:\n",
    "factors=(factors-np.mean(factors,axis=0))/np.var(factors,axis=0)**.5\n",
    "#X_with_ones = np.hstack((np.ones((factors.shape[0], 1)), factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "######################################################\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression against each one single time, BTC/USD\n",
    "factor_test=factors\n",
    "r=[]\n",
    "for i in range(8):\n",
    "    R_test=R[i]\n",
    "    beta_test=np.linalg.lstsq(factor_test,R_test.T, rcond=None)\n",
    "    S=np.dot(factors,beta_test[0])\n",
    "    res_test=np.linalg.norm(R_test-S)**2\n",
    "    r.append(1-res_test/np.linalg.norm(R_test)**2)\n",
    "r=np.array(r)\n",
    "print(np.max(r), np.min(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "for i in range(6):\n",
    "    fac=factors.T[i].reshape(-1,1)\n",
    "    ret=R[8].T\n",
    "    #print(fac.shape)\n",
    "    reg.fit(fac,ret)\n",
    "    temp_beta=reg.coef_[0]\n",
    "    temp_inter=reg.intercept_\n",
    "    print(temp_beta, temp_inter)\n",
    "    print(reg.score(fac,ret))\n",
    "    plt.plot(fac, ret,'o')\n",
    "    plt.plot(fac, temp_beta*fac + temp_inter, 'r', label='Fitted line')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(88):\n",
    "    print(coins[int(t/2)],quotes[t%2])\n",
    "    plt.plot(range(len(R)), R.T[t])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
