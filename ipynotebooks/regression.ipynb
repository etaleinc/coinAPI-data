{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/home/fbuonerba/codes/')\n",
    "from mp_functions import upload_log_return, upload_factor_loadings, request_rates\n",
    "from coinapi_v1 import CoinAPIv1\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import calendar\n",
    "import json\n",
    "import urllib.request\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import cvxopt\n",
    "from cvxopt import matrix, solvers\n",
    "from cvxopt.blas import dot\n",
    "from cvxopt.solvers import qp\n",
    "\n",
    "solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ETH' 'XRP' 'BCH' 'EOS' 'XLM' 'LTC' 'ADA' 'XMR' 'IOTA' 'TRX' 'ETC' 'DASH'\n",
      " 'NEO' 'XEM' 'BNB' 'ZEC' 'OMG' 'LSK' 'ZRX' 'QTUM' 'DOGE' 'BTS' 'DGB' 'ICX'\n",
      " 'STEEM' 'AE' 'WAVES' 'SC' 'REP' 'PPT' 'GNT' 'STRAT']\n"
     ]
    }
   ],
   "source": [
    "#load coin names - it removes those with some outliers in historical data\n",
    "with open('/home/fbuonerba/codes/meta_data/new_coins.txt') as ff:\n",
    "    coins=json.load(ff)\n",
    "bad=['NPXS','MKR','VET','RHOC', 'ONT', 'ZIL', 'NANO', 'BAT','BCD','XTZ']\n",
    "coins=np.array(coins)\n",
    "where=[i for i in range(len(coins)) if coins[i] in bad]\n",
    "coins=np.delete(coins, where)\n",
    "\n",
    "prettybad=['BTC','BCN','DCR','BTG','BTM','XVG']\n",
    "prettywhere=[i for i in range(len(coins)) if coins[i] in prettybad]\n",
    "coins=np.delete(coins, prettywhere)\n",
    "quotes=['BTC']\n",
    "print(coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads daily log-returns from beginning to end.\n",
    "#W keeps track of coin indices for which no historical\n",
    "#data is available, and removes them from final returns array.\n",
    "#it returns W and time-series of log-returns (without pathological ones).\n",
    "#With the current 32 coins stored in the above array coins, W is always empty.\n",
    "#It need not be if one adds further coins.\n",
    "\n",
    "#INPUT: beginning, end\n",
    "#OUTPUT: array W , time-series of log-returns\n",
    "\n",
    "def get_returns(beg,end):\n",
    "    t=beg\n",
    "    matrix=[]\n",
    "    while t<=end+1:\n",
    "        ret_t=[]\n",
    "        for base in coins:\n",
    "            for quote in quotes:\n",
    "                returns=upload_log_return(t, base, quote, 86400)\n",
    "                if np.isnan(returns)==True:\n",
    "                    returns=0\n",
    "                ret_t.append(returns)\n",
    "        matrix.append(ret_t)\n",
    "        t+=86400\n",
    "    R=np.array(matrix)\n",
    "    norms=np.linalg.norm(R, axis=0)\n",
    "    W=np.where(norms==0)\n",
    "    R=np.delete(R, W, axis=1) \n",
    "    return(W, R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads factor loadings, computed using data from beginning to end\n",
    "#the default time interval end-beg= 84 days.\n",
    "#there are 3 indices: averaged, exact, naive. \n",
    "#Each correspond to a different technique to compute factor loadings.\n",
    "#Averaged factors are those that performed best in tests; exact factors are as in Barra.\n",
    "#W is the list of pathological coins as computed in get_returns\n",
    "#Returns std of log-returns over time interval, and the factor loadings\n",
    "\n",
    "#INPUT: beginning, end, array W from above, index. By default end-beg=84days\n",
    "#OUTPUT: std of log-returns from beg to end, factor loadings\n",
    "\n",
    "factors=[]\n",
    "keys=['returns_variance', 'returns_strength', 'rates_high_low','turnover', 'log_marketcap']\n",
    "naive_folder='/home/fbuonerba/factor_loadings/naive_factors_'\n",
    "exact_folder='/home/fbuonerba/factor_loadings/exact_factors_'\n",
    "\n",
    "def get_raw_factors(beg,end,W=[],index='averaged'):\n",
    "    folder='/home/fbuonerba/factor_loadings/averaged_factors_'\n",
    "    if index=='exact':\n",
    "        folder=exact_folder\n",
    "    elif index=='naive':\n",
    "        folder=naive_folder\n",
    "    factors=[]\n",
    "    std=[]    \n",
    "    R=get_returns(beg, end)[1].T\n",
    "    for coin in coins:\n",
    "        for quote in quotes:\n",
    "            with open(folder+coin+'_'+quote+'_'+str(beg)+'_'+str(end)+'_86400.txt') as data:\n",
    "                fac=json.load(data)\n",
    "            ordr=[]\n",
    "            for key in keys:\n",
    "                if key=='returns_variance':\n",
    "                    E=fac[key]**.5\n",
    "                    std.append(E)\n",
    "                elif key=='returns_strength':#log(p_T/p_t)\n",
    "                    E=np.sum(R[np.where(coins==coin)])#summing over time\n",
    "                else:    \n",
    "                    E=fac[key]\n",
    "                ordr.append(E)\n",
    "            factors.append(ordr)\n",
    "    factors=np.array(factors)\n",
    "    std=np.array(std)\n",
    "    factors=np.delete(factors, W, axis=0)\n",
    "    std=np.delete(std, W, axis=0)\n",
    "    std=std.reshape(-1,1)\n",
    "    factors[np.where(np.isnan(factors)==True)]=0\n",
    "    return(std, factors)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processes factor loadings in two possible ways:\n",
    "#preprocess 1: scales so that each factor has mean zero and std one in the coin direction\n",
    "#preprocess 2: for each factor, coins are ranked by the value of the factor; then\n",
    "#rankings are scaled to (-1,1) and these numbers replace the actual factor.\n",
    "\n",
    "#INPUT: beginning, end, preprocess style, index of factor loadings\n",
    "#OUTPUT: std of log-returns from beg to end, processed factor loadings\n",
    "\n",
    "def get_processed_factors(beg,end,W,preprocess=1, index='averaged'):\n",
    "    std, factors=get_raw_factors(beg,end,W, index)\n",
    "    if preprocess==2:\n",
    "        factors=np.argsort((np.argsort(factors, axis=0)), axis=0 )#order coins by factors \n",
    "        factors=2*factors/np.max(factors)-1 #scale so max=1, min=-1\n",
    "    else:\n",
    "        factors=(factors-np.mean(factors,axis=0))/np.std(factors,axis=0)\n",
    "    return(std, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits linear model for a given day and factor preprocessing style.\n",
    "#it uses statsmodels standard package.\n",
    "\n",
    "#INPUT: day, preprocess style, presence of weights in linear regression.\n",
    "#OUTPUT:log-returns on day; processed factor loadings on day;\n",
    "#std of log-returns over previous84 days; the whole WLS python object.\n",
    "\n",
    "def fit_model(day, preprocess=1, weights='Yes'):\n",
    "    W, returns=get_returns(day, day)\n",
    "    yday=day-86400#use only past data to compute factor loadings\n",
    "    returns=np.array(returns[0])#make returns array of correct dimension\n",
    "    std, factors=get_processed_factors(yday-(1522540800-1515283200),yday, W, preprocess)\n",
    "    factors=sm.add_constant(factors)\n",
    "    wt=1/std**2\n",
    "    if weights=='No':\n",
    "        wt=np.ones_like(std)\n",
    "    wls=sm.WLS(returns, factors, weights=wt).fit()\n",
    "    return(returns, factors, std, wls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute covariance matrix using the linear model on a given day.\n",
    "#for the previous 84 days, it computes the linear regression above.\n",
    "#it remember two things: \n",
    "#1) time-series of factor returns of regression:\n",
    "#since there are 5 factors, the total factor returns cover a 84x6 matrix, 6=5+1\n",
    "#accounts for intercept term. \n",
    "#2) time-series of residuals of each regression. \n",
    "#finally cov = X (cov(factor_returns)) X^t + diagonal (variance(residuals))\n",
    "#here X= factor loadings as computed on the last of the 84 days.\n",
    "\n",
    "#INPUT: day, preprocess style\n",
    "#OUTPUT: model covariance matrix\n",
    "\n",
    "def cov(day, preprocess=1):\n",
    "    day0=day-(1522540800-1515283200)\n",
    "    BETA=[]\n",
    "    RES=[]\n",
    "    RET=[]\n",
    "    days=int((1522540800-1515283200)/86400)\n",
    "    for t in range(days):\n",
    "        returns, factors, std, wls=fit_model(day0+86400*t, preprocess)\n",
    "        BETA.append(wls.params)\n",
    "        RES.append(returns-wls.predict() )\n",
    "        RET.append(returns)\n",
    "    BETA=np.array(BETA)\n",
    "    RES=np.array(RES)\n",
    "    RET=np.array(RET)\n",
    "    cov=np.dot( np.dot(factors, np.cov(BETA.T)), factors.T) \n",
    "    varian=np.var(RES, axis=0)#tested everything has positive eigenvalues\n",
    "    cov = cov + np.diag(varian)\n",
    "    return(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is sample covariance matrix.\n",
    "#It has been tested many times that this function and the previous one\n",
    "#do operate on the very same set of log-returns (no shift in historical data).\n",
    "#Moreover, all that is used to estimate cov(day) involves data up to day-1.\n",
    "\n",
    "#INPUT: day\n",
    "#OUTPUT:sample covarianec matrix\n",
    "\n",
    "def raw_cov(day):  \n",
    "    day0=day-(1522540800-1515283200)\n",
    "    W, ret = get_returns(day0, day-86400)\n",
    "    co=np.cov(ret.T)\n",
    "    return(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics about covariance matrix: returns max,min eigenvalues, and their ratio.\n",
    "\n",
    "#INPUT: covariance matrix\n",
    "#OUTPUT: max, min eigenvalues, max/min\n",
    "def covariance_stability(co):\n",
    "    eigenvalues=np.linalg.svd(co)[1]\n",
    "    mi=np.min(eigenvalues)\n",
    "    ma=np.max(eigenvalues)\n",
    "    condition=ma/mi\n",
    "    return(ma, mi, condition)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds optimal portfolio at given day using Markowitz theory.\n",
    "\n",
    "#INPUT: day, alpha, linear constraints: Gx<h, Ax=b, preprocess style, risk aversion.\n",
    "#OUTPUT: vector of weights for optimized portfolio.\n",
    "\n",
    "#remarks: risk aversion is set to 10^3 so weights tend to be between -1 and 1.\n",
    "#it solves quadratic problem -alpha.x + rho x^T.S.x (S=covariance matrix)\n",
    "\n",
    "def portfolio(day, alpha, G,h,A,b, preprocess=2, rho=10**3):\n",
    "    if preprocess==0:\n",
    "        covv=raw_cov(day)\n",
    "    else:\n",
    "        covv=cov(day, preprocess)\n",
    "    a=matrix(alpha)\n",
    "    S=matrix(covv)\n",
    "    G=matrix(G)\n",
    "    h=matrix(h)\n",
    "    #sol = solvers.qp(P,q,G,h,A,b)\n",
    "    # minimize xPx + qx subject to\n",
    "    #Gx < h\n",
    "    #Ax = b (A,b can be omitted)\n",
    "    if np.linalg.matrix_rank(A)==0:\n",
    "        sol=np.array(qp(rho*S, -a, G, h)['x'])\n",
    "    else:\n",
    "        A=matrix(A)\n",
    "        b=matrix(b)\n",
    "        sol=np.array(qp(rho*S, -a, G, h, A, b)['x'])\n",
    "    return(sol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the total return of optimal portfolio held from day_init until day_end.\n",
    "\n",
    "#INPUT: portfolio, day_init, day_end, lags in days (useless here)\n",
    "#OUTPUT: portfolio, time-series of daily realized returns.\n",
    "def portfolio_returns(portf, day_init, day_end, day_lag=0):\n",
    "    days= int((day_end-day_init)/86400)\n",
    "    lag=86400*day_lag\n",
    "    ret=get_returns(day_init+lag, day_end+lag-1)[1]\n",
    "    realized_returns=np.dot(ret, portf)\n",
    "    return(portf, realized_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes statistics attached to the performance of the portfolio.\n",
    "\n",
    "#INPUT: portfolio, time-series of its realized daily returns\n",
    "#OUTPUT: mean, std, sharpe ratio of time-series of realized returns,\n",
    "#gross and net values of the portfolio.\n",
    "def portfolio_stats(portfolio, returns):\n",
    "    mean=np.mean(returns)\n",
    "    std=np.std(returns)\n",
    "    sharpe=mean/std\n",
    "    LBV=np.sum(portfolio.clip(min=0))\n",
    "    SBV=-np.sum(portfolio.clip(max=0))\n",
    "    gross=LBV+SBV\n",
    "    net=LBV-SBV\n",
    "    return(mean, std, sharpe, gross, net)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes evolving portfolio in period of time between day_init and day_end.\n",
    "#Everyday it creates optimal portfolio for that day, and returns an array of portfolios.\n",
    "#It does so by running 'portfolio' function every day.\n",
    "\n",
    "#INPUT: day_init, day_end, same other variables as portfolio.\n",
    "#OUTPUT: time-series of daily optimized portfolios.\n",
    "\n",
    "def evol_portfolio(day_init, day_end, alpha, G,h,A,b, preprocess=2, rho=10**3):\n",
    "    portf=[]\n",
    "    days=int((day_end-day_init)/86400)\n",
    "    for t in range(days+1):#day_end is included.\n",
    "        portf.append(portfolio(day_init+t*86400, alpha, G,h,A,b, preprocess, rho))\n",
    "    portf=np.array(portf)[:,:,0].T\n",
    "    return(portf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes realized returns of portfolio that is evolving every day.\n",
    "#for every day, it computes dot(portfolio(day), returns(day)).\n",
    "#there is a lag option, so that it could actually compute:\n",
    "# dot (portfolio(day), returns(day+lag))\n",
    "\n",
    "#INPUT: time-series of portfolios, day_init, day_end, number of days lag.\n",
    "#OUTPUT: same time-series of portfolios, time-series of realized returns.\n",
    "\n",
    "def evol_portfolio_returns(portf, day_init, day_end, day_lag=0):\n",
    "    days= int((day_end-day_init)/86400)\n",
    "    lag=86400*day_lag\n",
    "    returns=get_returns(day_init+lag, day_end+lag)[1]\n",
    "    einstein_returns=np.einsum('ij,ji->i', returns, portf)\n",
    "    #realized_returns=np.dot(returns, portf).diagonal()---same as einsum.\n",
    "    return(portf, einstein_returns)#returns latest portfolio and timeseries of returns\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute statistics attached to performance of evolving portfolio.\n",
    "\n",
    "#INPUT: evolving portfolio, its realized returns time-series.\n",
    "#OUTPUT: mean, std, sharpe ratio of realized returns, average turnover of portfolio,\n",
    "#average gross, average net (all averages over time interval under consideration).\n",
    "\n",
    "def evol_portfolio_stats(portfolio, returns):\n",
    "    mean=np.mean(returns)\n",
    "    std=np.std(returns)\n",
    "    sharpe=mean/std\n",
    "    diff= portfolio[:, 1:]-portfolio[:, :-1]\n",
    "    avg_turnover=np.mean( np.sum(np.abs(diff), axis=0) )\n",
    "    LBV=np.sum(portfolio.clip(min=0), axis=0)\n",
    "    SBV=-np.sum(portfolio.clip(max=0), axis=0)\n",
    "    gross=np.mean(LBV+SBV)\n",
    "    net=np.mean(LBV-SBV)\n",
    "    return(mean, std, sharpe, avg_turnover, gross, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default parameters one can start with.\n",
    "day=1522540800 + 85*86400#June 24\n",
    "day0=day-(1522540800-1515283200)#April 1\n",
    "num=32\n",
    "G=-np.zeros((num,num))\n",
    "h=np.zeros(num)\n",
    "A=np.zeros(num).reshape(1,-1)\n",
    "b=0.0\n",
    "alpha=np.zeros(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################Chapter1######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAC=[]\n",
    "for t in range(90):\n",
    "    FAC.append(get_processed_factors(day0+t*86400, day+t*86400,[],2)[1])\n",
    "FAC=np.array(FAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(32):\n",
    "    for f in range(5):\n",
    "        plt.plot(FAC[:,c,f])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=[]\n",
    "BETA=[]\n",
    "FAC=[]\n",
    "RES=[]\n",
    "RE=[]\n",
    "manual_r2=[]\n",
    "for t in range(90):\n",
    "    rets,factors,std,wls=fit_model(day0+t*86400, 2)\n",
    "    weights=std.reshape(1,-1)[0]**-1\n",
    "    R2.append(wls.rsquared)\n",
    "    BETA.append(wls.params)\n",
    "    FAC.append(factors)\n",
    "    RES.append(rets-wls.predict())\n",
    "    RE.append(rets)\n",
    "    ###statsmodels R2 computation\n",
    "    RSS= np.sum((weights*(rets-wls.predict()))**2 )#weighted sum\n",
    "    weighted_mean=np.average(rets, weights=weights**2)#weighted mean\n",
    "    TSS=np.sum((weights*(rets-weighted_mean))**2)#weighted sum    \n",
    "    manual_r2.append(1-RSS/TSS)\n",
    "    ###\n",
    "R2=np.array(R2)\n",
    "manual_r2=np.array(manual_r2)\n",
    "RE=np.array(RE)\n",
    "RES=np.array(RES)\n",
    "FAC=np.array(FAC)\n",
    "BETA=np.array(BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(R2), np.max(np.abs(R2-manual_r2)))\n",
    "plt.scatter(range(len(R2)), R2)\n",
    "plt.scatter(range(len(R2)), manual_r2)\n",
    "plt.show()\n",
    "for c in range(32):\n",
    "    print(coins[c])\n",
    "    for j in range(6):\n",
    "        FFF=FAC[:,c,j].T*BETA[:,j]\n",
    "        print(np.corrcoef(RE.T[c], FFF))\n",
    "        plt.plot(RE.T[5])\n",
    "        plt.plot(FFF)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=np.array(BETA)\n",
    "R2=np.array(R2)\n",
    "FAC=np.array(FAC)\n",
    "\n",
    "covv=cov(day0+86400*150)\n",
    "covv2=cov2(day0+86400*150)\n",
    "raw_covv=raw_cov(day0+86400*150)\n",
    "\n",
    "corr=statsmodels.stats.moment_helpers.cov2corr(covv)\n",
    "corr2=statsmodels.stats.moment_helpers.cov2corr(covv)\n",
    "raw_corr=statsmodels.stats.moment_helpers.cov2corr(raw_covv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(raw_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factor loadings for each coin\n",
    "for c in range(32):\n",
    "    plt.plot(FAC[:,c])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumulative factor returns\n",
    "cumbeta=np.cumsum(beta, axis=0)    \n",
    "keyss=['intercept','returns_std', 'returns_strength', 'rates_high_low','turnover', 'log_marketcap',]\n",
    "x=range(len(beta))\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "for i in range(6):\n",
    "    ax.plot(x,cumbeta[:,i], linewidth=1.5, label=keyss[i])\n",
    "ax.legend(loc='lower right')    #plt.show()\n",
    "#plt.savefig('factor_returns.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=np.array(R2)\n",
    "print(np.mean(R2), np.std(R2))\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.scatter(range(len(R2)), R2, color='black')\n",
    "plt.axhline(y=np.mean(R2), color='red', linestyle='-', label='average R2 = 0.23')\n",
    "ax.legend(loc='lower right')\n",
    "#plt.savefig('r2_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(10):\n",
    "    dayt=day+t*7*86400\n",
    "    co1=cov(dayt, 1)\n",
    "    co2=cov(dayt, 2)\n",
    "    co3=raw_cov(dayt)\n",
    "    print('+++++++')\n",
    "    print(covariance_stability(co1))\n",
    "    print(covariance_stability(co2))\n",
    "    print(covariance_stability(co3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############Chapter2###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):#ideally std/gross should be very small.\n",
    "    alpha=np.random.randn(32)\n",
    "    day30=day+86400*30\n",
    "    port=portfolio(day, alpha, G,h,A,b, 2)\n",
    "    port_sample=portfolio(day, alpha, G,h,A,b, 0)#sample\n",
    "    ret=portfolio_returns(port, day, day30)[1]\n",
    "    ret_sample=portfolio_returns(port_sample, day, day30)[1]\n",
    "    st=portfolio_stats(port, ret)\n",
    "    st_sample=portfolio_stats(port_sample, ret_sample)\n",
    "    print(st[1]/st[3])\n",
    "    print(st_sample[1]/st_sample[3])\n",
    "    print('======')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=np.zeros(num)\n",
    "for i in range(2,11):\n",
    "    alpha[:i]=1\n",
    "    portf=evol_portfolio(day, day+90*86400, alpha, G,h,A,b,'box')#up to Sept 22\n",
    "    pr=evol_portfolio_returns(portf, day, day + 86400*90)\n",
    "    portfraw=evol_portfolio(day, day+90*86400, alpha, G,h,A,b, 'raw')\n",
    "    prraw=evol_portfolio_returns(portfraw, day, day + 86400*90)\n",
    "    print('model', np.dot(portf, alpha))\n",
    "   # rreturns=get_returns(day, day+90*86400)[1]\n",
    "    print('sample', np.dot(portfraw, alpha))\n",
    "    #print('alpha:', alpha)\n",
    "    print('mean_realized_ret, std_realized_ret, sharpe, avg_turnover, avg_gross, avg_net')\n",
    "    print('model_cov', evol_portfolio_stats(pr[0],pr[1]))\n",
    "    print('sample_cov', evol_portfolio_stats(prraw[0],prraw[1]))\n",
    "    #print('*****************************')\n",
    "    plt.plot(np.cumsum(pr[1]))\n",
    "    plt.plot(np.cumsum(prraw[1]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(5):\n",
    "    rho=10**-x\n",
    "    alpha=np.zeros(32)\n",
    "    alpha[:5] = 1\n",
    "    port, pp = portfolio_returns(alpha, day, day+140*86400, None , 0.01)\n",
    "    print(port.T)\n",
    "    pp=np.array([x[0] for x in pp])\n",
    "    cumpp=np.cumsum(pp)\n",
    "    ssstd=[]\n",
    "    mmmean=[]\n",
    "    plt.plot(cumpp)\n",
    "    plt.show()\n",
    "    for t in range(1,140):\n",
    "        ssstd.append(np.std(cumpp[:t]))\n",
    "        mmmean.append(np.mean(cumpp[:t]))\n",
    "    plt.plot(mmmean)\n",
    "    plt.plot(ssstd)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=np.zeros(32)\n",
    "alpha[0]=1\n",
    "\n",
    "#cc=np.array(coins).reshape(-1,1)\n",
    "day=1522540800\n",
    "day_end=day + 139*86400\n",
    "#alpha/=np.sum(alpha)\n",
    "port=portfolio(day_end, alpha)[0]\n",
    "print(np.sum(np.abs(port)))\n",
    "for h in range(32):\n",
    "    print(coins[h+1], '&', round(port[h][0],2), '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ro(x):\n",
    "    return(round(x,4))\n",
    "\n",
    "day=1522540800\n",
    "day_end=day + 140*86400\n",
    "alpha=np.zeros(32)\n",
    "for i in range(1,10):\n",
    "    alpha[:i]=1\n",
    "    alpha/=np.sum(alpha)\n",
    "    opt_m, opt_std, opt_sh=portfolio_stats(alpha, day, day_end)\n",
    "    raw_m, raw_std, raw_sh=portfolio_stats(alpha, day, day_end,'raw')\n",
    "    print(i,'&',ro(opt_m),'&',ro(raw_m),'&',ro(opt_std),'&',ro(raw_std),'&',ro(opt_sh),'&',ro(raw_sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=1522540800\n",
    "r2=[]\n",
    "beta=[]\n",
    "inter=[]\n",
    "retur=[]\n",
    "errors=[]\n",
    "for t in range(140):\n",
    "    ret, _ , _ , wls=fit_model(day+86400*t)#, weights='No')\n",
    "    #print(wls.params)\n",
    "    #print(wls.summary())\n",
    "    retur.append(ret)\n",
    "    errors.append(ret-wls.predict())\n",
    "    #r2.append(wls.rsquared)\n",
    "    beta.append(wls.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=np.array(errors)\n",
    "et=errors.T\n",
    "rt=(np.array(retur)).T\n",
    "l=et.shape[1]\n",
    "autoR=[]\n",
    "autoE=[]\n",
    "for i in range(32):\n",
    "    autoE.append(np.corrcoef(et[i][1:], et[i][:-1])[0,1])\n",
    "    autoR.append(np.corrcoef(rt[i][1:], rt[i][:-1])[0,1])\n",
    "    print(np.mean(et[i][1:]- et[i][:-1]) / np.std(et[i][1:]- et[i][:-1]))\n",
    "    print(np.mean(rt[i][1:]- rt[i][:-1]) / np.std(rt[i][1:]- rt[i][:-1]))\n",
    "    print('+++++')\n",
    "    #plt.scatter(range(l-1), np.random.normal(0,np.std(et[i]), l-1))\n",
    "    #plt.scatter(range(l-1), et[i][1:]- et[i][:-1])\n",
    "    plt.show()\n",
    "\n",
    "print(np.mean(autoE))#/ np.std(autoE))\n",
    "print(np.mean(autoR))#/ np.std(autoR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyss=['intercept','returns_std', 'returns_strength', 'rates_high_low','turnover', 'log_marketcap',]\n",
    "x=range(140)\n",
    "beta=np.array(beta)\n",
    "cumbeta=np.cumsum(beta.T, axis=1)\n",
    "print(beta.T-cumbeta)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "#line1, = ax.plot(x, np.sin(x), '--', linewidth=2,\n",
    "                 #label='Dashes set retroactively')\n",
    "#line1.set_dashes(dashes)\n",
    "for i in range(6):\n",
    "    ax.plot(x,cumbeta[i], linewidth=1.5, label=keyss[i])\n",
    "ax.legend(loc='lower right')    #plt.show()\n",
    "plt.savefig('factor_returns.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mr2=np.mean(r2)\n",
    "print(mr2)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "#line1, = ax.plot(x, np.sin(x), '--', linewidth=2,\n",
    "                 #label='Dashes set retroactively')\n",
    "#line1.set_dashes(dashes)\n",
    "ax.scatter(range(140), r2, color='black')\n",
    "plt.axhline(y=mr2, color='red', linestyle='-', label='average R2 = 0.24')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('r2_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs =plt.subplots(2,1)\n",
    "clust_data = [coins, ]\n",
    "collabel=(\"col 1\", \"col 2\", \"col 3\")\n",
    "axs[0].axis('tight')\n",
    "axs[0].axis('off')\n",
    "the_table = axs[0].table(cellText=clust_data,colLabels=collabel,loc='center')\n",
    "print(coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=1522540800\n",
    "alpha=np.zeros(32)\n",
    "alpha[0]=1\n",
    "RET=[]\n",
    "RET_raw=[]\n",
    "for i in range(1,10):\n",
    "    alpha[:i]=1\n",
    "    for t in range(140):\n",
    "        RET.append(portfolio(day+t*86400, alpha)[1])\n",
    "        RET_raw.append(portfolio(day+t*86400, alpha,'raw')[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(RET)-np.array(RET_raw)\n",
    "us=0\n",
    "them=0\n",
    "for x in X:\n",
    "    if x>0:\n",
    "        us+=1\n",
    "    else:\n",
    "        them+=1\n",
    "print(us, them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#stats for log_returns in terms of BTC\n",
    "methods=['averaged','barra']\n",
    "weights=[0,1]\n",
    "T=list(range(20))\n",
    "beg=[1522540800+t*604800 for t in T]\n",
    "end=[1522540800+(t+1)*604800 for t in T]\n",
    "beg1=[1515283200+t*604800 for t in T]\n",
    "end1=[1522540800+t*604800 for t in T]\n",
    "###statsmodels works if do one regression per day, i.e. y a vector###\n",
    "ret=[]\n",
    "errors=[]\n",
    "predictions=[]\n",
    "factor_loadings=[]\n",
    "victory=0\n",
    "victory1=0\n",
    "victory2=0\n",
    "rsquares=[]\n",
    "print('r2_naive', 'r2_exact', 'r2_averaged')\n",
    "for j in range(len(T)):\n",
    "    W,R=get_returns(beg[j],end[j])\n",
    "    print(W)\n",
    "    sys.stdout.flush()\n",
    "    std, factors=get_processed_factors(beg1[j],end1[j],W, 'naive')\n",
    "    std, factors1=get_processed_factors(beg1[j],end1[j],W,'exact')\n",
    "    std, factors2=get_processed_factors(beg1[j],end1[j],W,'averaged')\n",
    "    print('**********')\n",
    "    sys.stdout.flush()\n",
    "    X=factors\n",
    "    X1=factors1\n",
    "    X2=factors2\n",
    "    X = sm.add_constant(X)\n",
    "    X1 = sm.add_constant(X1)\n",
    "    X2 = sm.add_constant(X2)\n",
    "    for i in range(7):\n",
    "        Y=R[i].T\n",
    "        ret.append(Y)\n",
    "        #est_nowt=sm.WLS(Y,X).fit()\n",
    "        sss=1/std**2\n",
    "        est_wt=sm.WLS(Y,X, weights=sss).fit()\n",
    "        est_wt1=sm.WLS(Y,X1, weights=sss).fit()\n",
    "        est_wt2=sm.WLS(Y,X2, weights=sss).fit()\n",
    "        beta2=est_wt2.params\n",
    "        factor_loadings.append(beta2)\n",
    "        Y_hat=est_wt2.predict()\n",
    "        error=est_wt2.predict()-Y\n",
    "        predictions.append(Y_hat)\n",
    "        errors.append(error)\n",
    "    #look for heteroskedasticity!\n",
    "    #plt.scatter(est_nowt.predict(),error)\n",
    "    #plt.scatter(est_wt.predict(), error)\n",
    "    #plt.show()\n",
    "    #print(est_wt.summary())\n",
    "        r2=est_wt.rsquared\n",
    "        r21=est_wt1.rsquared\n",
    "        r22=est_wt2.rsquared\n",
    "        rsquares.append(r22)\n",
    "        #print(r2, r21, r22)\n",
    "        argm=np.argmax(np.array([r21, r22]))\n",
    "        if argm==0:\n",
    "            victory+=1\n",
    "        elif argm==1:\n",
    "            victory1+=1\n",
    "        else:\n",
    "            victory2+=1\n",
    "print(victory, victory1, victory2)\n",
    "    \n",
    "#print('times naive won:', victory, 'times barra won', victory1)\n",
    "    \n",
    "        \n",
    "#    #check errors are independent of factors!\n",
    "#     for k in range(X.shape[1]):\n",
    "#         if k>0:\n",
    "#             print(keys[k-1])\n",
    "#         plt.scatter(range(len(X.T[k])),X.T[k])#, error)\n",
    "#         plt.show()\n",
    "\n",
    "####check that errors are more or less iid by plotting covariance matrix####\n",
    "\n",
    "rsquares=np.array(rsquares)\n",
    "print(rsquares)\n",
    "print(np.min(rsquares), np.max(rsquares), np.mean(rsquares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 in memory is factor loadings at final time - we can use that\n",
    "import statsmodels\n",
    "predictions=np.array(predictions)\n",
    "errors=np.array(errors)\n",
    "ret=np.array(ret)\n",
    "factor_loadings=np.array(factor_loadings)\n",
    "factor_cov=np.cov(factor_loadings.T)\n",
    "#factor_cov.shape\n",
    "est_covariance=np.dot( np.dot(X2, np.cov(factor_loadings.T)), X2.T) \n",
    "delta=np.var(errors, axis=0)\n",
    "est_covariance+=np.sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(raw_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])diag(delta)\n",
    "raw_corr=np.corrcoef(ret.T)\n",
    "raw_est_corr=np.corrcoef(predictions.T)\n",
    "est_corr=statsmodels.stats.moment_helpers.cov2corr(est_covariance)\n",
    "print('first plots Corr(raw_returns), second plots Corr(predicted_returns), \\\n",
    "third plots Factors.Corr(beta).Factors^T + Diag(err^2) ')\n",
    "#print(raw_corr.shape, raw_est_corr.shape, est_corr.shape)\n",
    "#heatmap of raw correlation\n",
    "\n",
    "#ZZZ.figure.savefig(\"raw_corr.png\")\n",
    "#heatmap of raw correlation\n",
    "\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(raw_est_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "#ZZZ.figure.savefig(\"raw_estimated_corr.png\")\n",
    "#heatmap of estimated correlation\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(est_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "#ZZZ.figure.savefig(\"model_corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_difference=est_corr-raw_corr\n",
    "corr_difference\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(corr_difference[:15,:15], vmin=-0.00001, vmax=0.00001, annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "ax.set_title('model_estimated_correlations - raw_correlations')\n",
    "ZZZ.figure.savefig(\"correlation_difference.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_tomorrow=ret[1:]\n",
    "ret_today=ret[:-1]\n",
    "err_tomorrow=errors[1:]\n",
    "err_today=errors[:-1]\n",
    "serial_ret_corr=np.corrcoef(ret_tomorrow.T , ret_today.T)[:32,32:].diagonal()\n",
    "serial_error_corr=np.corrcoef(err_tomorrow.T , err_today.T)[:32,32:].diagonal()\n",
    "ser_ret_m=np.mean(serial_ret_corr)\n",
    "ser_ret_std=np.std(serial_ret_corr)\n",
    "ser_err_m=np.mean(serial_error_corr)\n",
    "ser_err_std=np.std(serial_error_corr)\n",
    "print('mean and std for serial return correlations')\n",
    "print(ser_ret_m, ser_ret_std)\n",
    "print('mean and std for serial residual correlations')\n",
    "print(ser_err_m, ser_err_std)\n",
    "#plt.xlim(-1e-3,1e-3)\n",
    "#plt.ylim(-1e-3,1e-3)\n",
    "plt.ylabel('serial error corr')\n",
    "plt.xlabel('serial return corr')\n",
    "plt.xticks(rotation=90)\n",
    "plt.scatter(serial_ret_corr,serial_error_corr)\n",
    "# plt.savefig(\"serial_correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above.\n",
    "ser_corr_ret=[]\n",
    "ser_corr_err=[]\n",
    "for c in range(32):\n",
    "    ser_corr_ret.append(np.corrcoef(ret.T[c][1:], ret.T[c][:-1])[0,1])\n",
    "    ser_corr_err.append(np.corrcoef(errors.T[c][1:], errors.T[c][:-1])[0,1])\n",
    "ser_corr_ret=np.array(ser_corr_ret)\n",
    "plt.scatter(ser_corr_ret, ser_corr_err)\n",
    "plt.savefig(\"serial.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.odr\n",
    "def f(B,x):\n",
    "    return B[0]*x + B[1]\n",
    "linear=scipy.odr.Model(f)\n",
    "data=scipy.odr.Data(serial_ret_corr,serial_error_corr)#order is x,y for data.\n",
    "odr = scipy.odr.ODR(data, linear, beta0=[0, 0])\n",
    "out=odr.run()\n",
    "out.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in range(32):\n",
    "    Y=ret.T[c].T\n",
    "    Y_=Y[7:]\n",
    "    matrix_c=np.append(Y[:7], np.zeros(133))\n",
    "    for t in range(1,133):\n",
    "        row=np.append(np.append(np.zeros(t), Y[t:t+7]), np.zeros(133-t))\n",
    "        matrix_c=np.vstack((matrix_c, row.T))\n",
    "#     print(Y_)\n",
    "#     for j in range(133):\n",
    "#         print(matrix_c[j])\n",
    "    ols=sm.OLS(Y_, X).fit()\n",
    "    print(ols.params)\n",
    "    print(ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoregressive model for returns, weekly.\n",
    "#R_t = linear function in (R_{t-1},...,R_{t-7})\n",
    "for t in range(ret.shape[0]-7):\n",
    "    Y=ret[t+7]\n",
    "    X=ret[t:t+7].T\n",
    "    ar7=sm.OLS(Y,X).fit()\n",
    "    #print(ar7.rsquared)\n",
    "import statsmodels.tsa.ar_model as AR\n",
    "for t in range(32):\n",
    "    lag=7\n",
    "    Y=ret.T[t]\n",
    "    ar=AR.AR(Y).fit(maxlag=lag)\n",
    "    Y_hat=ar.predict()\n",
    "    RES=Y[lag:]-Y_hat\n",
    "    TSS=np.sum((Y-np.mean(Y))**2)\n",
    "    RSS=np.sum((RES-np.mean(RES))**2)\n",
    "    R2=1-RSS/TSS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
