{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/home/fbuonerba/codes/')\n",
    "from mp_functions import upload_log_return, upload_factor_loadings\n",
    "from coinapi_v1 import CoinAPIv1\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import calendar\n",
    "import json\n",
    "import urllib.request\n",
    "import multiprocessing as mp\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BTC' 'ETH' 'XRP' 'BCH' 'EOS' 'XLM' 'LTC' 'ADA' 'XMR' 'IOTA' 'TRX' 'ETC'\n",
      " 'DASH' 'NEO' 'XEM' 'BNB' 'ZEC' 'OMG' 'LSK' 'ZRX' 'QTUM' 'DOGE' 'BTS'\n",
      " 'DGB' 'ICX' 'STEEM' 'AE' 'WAVES' 'SC' 'REP' 'PPT' 'GNT' 'STRAT']\n"
     ]
    }
   ],
   "source": [
    "with open('/home/fbuonerba/codes/meta_data/new_coins.txt') as ff:\n",
    "    coins=json.load(ff)\n",
    "bad=['NPXS','MKR','VET','RHOC', 'ONT', 'ZIL', 'NANO', 'BAT','BCD','XTZ']\n",
    "coins=np.array(coins)\n",
    "where=[i for i in range(len(coins)) if coins[i] in bad]\n",
    "coins=np.delete(coins, where)\n",
    "\n",
    "prettybad=['BCN','DCR','BTG','BTM','XVG']\n",
    "prettywhere=[i for i in range(len(coins)) if coins[i] in prettybad]\n",
    "coins=np.delete(coins, prettywhere)\n",
    "quotes=['BTC']\n",
    "print(coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sysm=[str(coin)+'_'+str(quote) for coin in coins for quote in quotes]\n",
    "def get_returns(beg,end):\n",
    "    #weights=0 or 1\n",
    "    t=beg\n",
    "    matrix=[]\n",
    "    while t<=end+1:\n",
    "        ret_t=[]\n",
    "        for base in coins:\n",
    "            for quote in quotes:\n",
    "                returns=upload_log_return(t, base, quote, 86400)\n",
    "                if np.isnan(returns)==True:\n",
    "                    #print(base, 'bad boy')\n",
    "                    returns=0\n",
    "                ret_t.append(returns)\n",
    "                #print(base,quote)\n",
    "        matrix.append(ret_t)\n",
    "        t+=86400\n",
    "    R=np.array(matrix)\n",
    "    norms=np.linalg.norm(R, axis=0)\n",
    "    W=np.where(norms==0)\n",
    "    ##careful here: W might change over different times!\n",
    "    ######\n",
    "    R=np.delete(R, W, axis=1) \n",
    "    #std=np.std(R, axis=0)\n",
    "    #return degenerate_indices, returns\n",
    "    return(W, R)\n",
    "\n",
    "#####W[0]=those pairs for which no trading activity is recorded\n",
    "#VET,NPXS have no data for this time period. Indeed they were ranked low on cmc.\n",
    "#then BTC has no data vs BTC, the rest have no data vs USD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Factors: January to April#####\n",
    "#####log_mkcap and coin_ratio computed averaging.\n",
    "#####Those are the good ones!\n",
    "\n",
    "########removing coin ratio to see what happens!!\n",
    "\n",
    "factors=[]\n",
    "keys=['returns_variance', 'returns_strength', 'rates_high_low','turnover', 'log_marketcap']#,'coin_ratio']\n",
    "naive_folder='/home/fbuonerba/factor_loadings/naive_factors_'\n",
    "#folder='/home/fbuonerba/factor_loadings/averaged_factors_'\n",
    "exact_folder='/home/fbuonerba/factor_loadings/exact_factors_'\n",
    "def get_raw_factors(beg,end,W,index='averaged'):\n",
    "    folder='/home/fbuonerba/factor_loadings/averaged_factors_'\n",
    "    if index=='exact':\n",
    "        folder=exact_folder\n",
    "    elif index=='naive':\n",
    "        folder=naive_folder\n",
    "    factors=[]\n",
    "    std=[]\n",
    "    for coin in coins:\n",
    "        for quote in quotes:\n",
    "            with open(folder+coin+'_'+quote+'_'+str(beg)+'_'+str(end)+'_86400.txt') as data:\n",
    "                fac=json.load(data)\n",
    "            ordr=[]\n",
    "            for key in keys:\n",
    "                if key=='returns_variance':\n",
    "                    E=fac[key]**.5\n",
    "                    std.append(E)\n",
    "                else:\n",
    "                    E=fac[key]\n",
    "                ordr.append(E)\n",
    "            factors.append(ordr)\n",
    "    factors=np.array(factors)\n",
    "    std=np.array(std)\n",
    "    factors=np.delete(factors, W, axis=0)\n",
    "    std=np.delete(std, W, axis=0)\n",
    "    std=std.reshape(-1,1)\n",
    "    #####here we do normalization using z-score along coin axis#####\n",
    "    factors[np.where(np.isnan(factors)==True)]=0\n",
    "    \n",
    "    ###There are two NaN entries, corresponding to coin ratio of BCD, 43rd position.\n",
    "    ###In a random cmc_historical, the supply is nan. Confirmed on cmc website chart:\n",
    "    #at the time BCD was doing poorly - in march it was ranked 1250th.\n",
    "    return(std, factors)\n",
    "\n",
    "def get_processed_factors(beg,end,W, index=None):\n",
    "    std, factors=get_raw_factors(beg,end,W, index)\n",
    "    factors=(factors-np.mean(factors,axis=0))/np.var(factors,axis=0)**.5\n",
    "    return(std, factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Factors: January to April#####\n",
    "#####log_mkcap and coin_ratio computed on the day.\n",
    "factors=[]\n",
    "new_keys=['returns_variance', 'returns_strength', 'rates_high_low','turnover']\n",
    "exact_keys=['log_mkcap_exact_','coin_ratio_exact_']\n",
    "new_folder='/home/fbuonerba/factor_loadings/naive_factors_'\n",
    "folder='/home/fbuonerba/factor_loadings/factors_'\n",
    "exact_folder='/home/fbuonerba/factor_loadings/exact_factors'\n",
    "def get_raw_barra_factors(beg,end,W):\n",
    "    factors=[]\n",
    "    std=[]\n",
    "    for coin in coins:\n",
    "        for quote in quotes:\n",
    "            with open(folder+coin+'_'+quote+'_'+str(beg)+'_'+str(end)+'_86400.txt') as data:\n",
    "                fac=json.load(data)\n",
    "            ordr=[]\n",
    "            for key in new_keys:\n",
    "                if key=='returns_variance':\n",
    "                    E=fac[key]**.5\n",
    "                    std.append(E)\n",
    "                else:\n",
    "                    E=fac[key]\n",
    "                ordr.append(E)\n",
    "            ####exact factors####\n",
    "            with open(exact_folder+exact_keys[0]+coin+'_'+quote+'_'+str(end)+'.txt') as ff:\n",
    "                exc=json.load(ff)\n",
    "            ordr.append(exc)\n",
    "            with open(exact_folder+exact_keys[1]+coin+'_'+str(end)+'.txt') as ff:\n",
    "                exc=json.load(ff)\n",
    "            ordr.append(exc)\n",
    "            factors.append(ordr)\n",
    "    factors=np.array(factors)\n",
    "    std=np.array(std)\n",
    "    factors=np.delete(factors, W, axis=0)\n",
    "    std=np.delete(std, W, axis=0)\n",
    "    std=std.reshape(1,-1)\n",
    "    factors[np.where(np.isnan(factors)==True)]=0\n",
    "    return(std, factors)\n",
    "    ###There are two NaN entries, corresponding to coin ratio of BCD, 43rd position.\n",
    "    ###In a random cmc_historical, the supply is nan. Confirmed on cmc website chart:\n",
    "    #at the time BCD was doing poorly - in march it was ranked 1250th.\n",
    "def get_processed_barra_factors(beg,end,W):\n",
    "    std, factors=get_raw_barra_factors(beg,end,W)\n",
    "    factors=(factors-np.mean(factors,axis=0))/np.var(factors,axis=0)**.5\n",
    "    return(std, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import cvxopt\n",
    "from cvxopt import matrix, solvers\n",
    "from cvxopt.blas import dot\n",
    "from cvxopt.solvers import qp\n",
    "\n",
    "solvers.options['show_progress'] = False\n",
    "def fit_model(day):\n",
    "    W, returns=get_returns(day, day)\n",
    "    returns=np.array(returns[0])\n",
    "    std, factors=get_processed_factors(day-(1522540800-1515283200),day, W)\n",
    "    factors=sm.add_constant(factors)\n",
    "    wt=1/std**2\n",
    "    wls=sm.WLS(returns, factors, weights=wt).fit()\n",
    "    return(returns, factors, std, wls)\n",
    "    \n",
    "\n",
    "def corr(day):\n",
    "    returns, factors, std, wls=fit_model(day)\n",
    "    beta=wls.params\n",
    "    residual=returns-wls.predict()\n",
    "    cor=np.dot( np.dot(factors, np.cov(beta.T)), factors.T) + np.diag(residual**2)\n",
    "    #diag=np.diag(  std.reshape(1,-1)[0]**2    )\n",
    "    #cor=np.dot( np.dot(factors, np.cov(beta.T)), factors.T) + diag\n",
    "    return(cor)\n",
    "\n",
    "def raw_corr(day):  \n",
    "    day0=day-(1522540800-1515283200)\n",
    "    RET=[]\n",
    "    while day0<day:\n",
    "        W, ret = get_returns(day0, day0)\n",
    "        RET.append(ret[0])\n",
    "        day0+=86400\n",
    "    RET=np.array(RET).T\n",
    "    cor=np.corrcoef(RET)\n",
    "    return(cor)\n",
    "\n",
    "def portfolio(day, alpha, method=None, mu=1):\n",
    "    cor=corr(day)\n",
    "    if method=='raw':\n",
    "        cor=raw_corr(day)\n",
    "    num=cor.shape[0]\n",
    "    a=matrix(alpha)\n",
    "    S=matrix(cor)\n",
    "    G=-matrix(np.eye(32))#forcing every weight positive\n",
    "    #G = matrix(0.0, (num,num))#these G,h do nothing but must be here.\n",
    "    \n",
    "    #G[::n+1] = -1.0 #this makes G=-id and creates inequality constraint.\n",
    "    h = matrix(0.0, (num,1))\n",
    "    A = matrix(1.0, (1,num))\n",
    "    b = matrix(1.0)\n",
    "    sol=np.array(qp(mu*S, -a, G, h, A, b)['x'])#solve -mu x.S.x + p_bar.x under Gx<=h, Ax=b\n",
    "    \n",
    "    ret=get_returns(day,day)[1][0]\n",
    "    realized_return=np.dot(ret, sol)\n",
    "    \n",
    "    return(sol, realized_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(alpha, day_init, day_end, method='None'):\n",
    "    days= int((day_end-day_init)/86400)\n",
    "    returns=[]\n",
    "    for t in range(days):\n",
    "        returns.append(portfolio(day_init+t*86400, alpha, method)[1])\n",
    "    returns=np.array(returns)\n",
    "    sharpe_ratio=np.mean(returns)/np.std(returns)\n",
    "    return(sharpe_ratio)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05968470272685436 -0.059337622961382536\n",
      "-0.07847954381513018 -0.0604569905307626\n",
      "-0.1152562900833619 -0.045951947397474234\n",
      "-0.09523852101681866 -0.03304310569729318\n",
      "-0.12666153396390298 -0.01636139636315351\n",
      "-0.1396780847483446 -0.043006311314621154\n",
      "-0.17746843215054886 -0.04388404928561527\n",
      "-0.1826443755356652 -0.06277305749404026\n",
      "-0.18358669976473657 -0.07101226324859544\n"
     ]
    }
   ],
   "source": [
    "day=1522540800\n",
    "day_end=day + 140*86400\n",
    "alpha=np.zeros(32)\n",
    "for i in range(1,10):\n",
    "    alpha[:i]=1\n",
    "    alpha/=np.sum(alpha)\n",
    "    opt_sharpe=sharpe_ratio(alpha, day, day_end)\n",
    "    raw_sharpe=sharpe_ratio(alpha, day, day_end,'raw')\n",
    "    print(opt_sharpe, raw_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Junk essentially####\n",
    "\n",
    "# day=1522540800\n",
    "# alpha=np.zeros(32)\n",
    "# alpha[0]=1\n",
    "# for i in range(1,10):\n",
    "#     alpha[:i]=1\n",
    "#     sharpe_ratios=[]#our model\n",
    "#     sharpe_ratios_raw=[]\n",
    "#     sharpe_ratios_alpha=[]\n",
    "#     for t in range(140):\n",
    "#         day_t=day+86400*t\n",
    "#         #get correlations\n",
    "#         cor=corr(day_t)\n",
    "#         raw_cor=raw_corr(day_t)\n",
    "#         #get portfolio weights and realized returns\n",
    "#         weights, returns= portfolio(day_t, alpha)\n",
    "#         weights_raw, returns_raw = portfolio(day_t, alpha, method='raw')\n",
    "#         alpha_return=np.dot(get_returns(day_t,day_t)[1], alpha)\n",
    "\n",
    "#         sharpe_ratios.append(sharpe_ratio(weights, returns, cor))\n",
    "#         sharpe_ratios_raw.append(sharpe_ratio(weights_raw, returns_raw, raw_cor))\n",
    "#         sharpe_ratios_alpha.append(sharpe_ratio(alpha.reshape(-1,1), alpha_return , cor))\n",
    "        \n",
    "#         sharpe=np.array([sharpe_ratios, sharpe_ratios_raw, sharpe_ratios_alpha])\n",
    "#         maxim=np.argmax(sharpe, axis=0)\n",
    "#         model=(maxim==0).sum()\n",
    "#         raw=(maxim==1).sum()\n",
    "#         alphaa=(maxim==2).sum()\n",
    "#     print(model, raw, alphaa)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=1522540800\n",
    "alpha=np.zeros(32)\n",
    "alpha[0]=1\n",
    "RET=[]\n",
    "RET_raw=[]\n",
    "for i in range(1,10):\n",
    "    alpha[:i]=1\n",
    "    for t in range(140):\n",
    "        RET.append(portfolio(day+t*86400, alpha)[1])\n",
    "        RET_raw.append(portfolio(day+t*86400, alpha,'raw')[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(RET)-np.array(RET_raw)\n",
    "us=0\n",
    "them=0\n",
    "for x in X:\n",
    "    if x>0:\n",
    "        us+=1\n",
    "    else:\n",
    "        them+=1\n",
    "print(us, them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#stats for log_returns in terms of BTC\n",
    "methods=['averaged','barra']\n",
    "weights=[0,1]\n",
    "T=list(range(20))\n",
    "beg=[1522540800+t*604800 for t in T]\n",
    "end=[1522540800+(t+1)*604800 for t in T]\n",
    "beg1=[1515283200+t*604800 for t in T]\n",
    "end1=[1522540800+t*604800 for t in T]\n",
    "###statsmodels works if do one regression per day, i.e. y a vector###\n",
    "ret=[]\n",
    "errors=[]\n",
    "predictions=[]\n",
    "factor_loadings=[]\n",
    "victory=0\n",
    "victory1=0\n",
    "victory2=0\n",
    "rsquares=[]\n",
    "print('r2_naive', 'r2_exact', 'r2_averaged')\n",
    "for j in range(len(T)):\n",
    "    W,R=get_returns(beg[j],end[j])\n",
    "    print(W)\n",
    "    sys.stdout.flush()\n",
    "    std, factors=get_processed_factors(beg1[j],end1[j],W, 'naive')\n",
    "    std, factors1=get_processed_factors(beg1[j],end1[j],W,'exact')\n",
    "    std, factors2=get_processed_factors(beg1[j],end1[j],W,'averaged')\n",
    "    print('**********')\n",
    "    sys.stdout.flush()\n",
    "    X=factors\n",
    "    X1=factors1\n",
    "    X2=factors2\n",
    "    X = sm.add_constant(X)\n",
    "    X1 = sm.add_constant(X1)\n",
    "    X2 = sm.add_constant(X2)\n",
    "    for i in range(7):\n",
    "        Y=R[i].T\n",
    "        ret.append(Y)\n",
    "        #est_nowt=sm.WLS(Y,X).fit()\n",
    "        sss=1/std**2\n",
    "        est_wt=sm.WLS(Y,X, weights=sss).fit()\n",
    "        est_wt1=sm.WLS(Y,X1, weights=sss).fit()\n",
    "        est_wt2=sm.WLS(Y,X2, weights=sss).fit()\n",
    "        beta2=est_wt2.params\n",
    "        factor_loadings.append(beta2)\n",
    "        Y_hat=est_wt2.predict()\n",
    "        error=est_wt2.predict()-Y\n",
    "        predictions.append(Y_hat)\n",
    "        errors.append(error)\n",
    "    #look for heteroskedasticity!\n",
    "    #plt.scatter(est_nowt.predict(),error)\n",
    "    #plt.scatter(est_wt.predict(), error)\n",
    "    #plt.show()\n",
    "    #print(est_wt.summary())\n",
    "        r2=est_wt.rsquared\n",
    "        r21=est_wt1.rsquared\n",
    "        r22=est_wt2.rsquared\n",
    "        rsquares.append(r22)\n",
    "        #print(r2, r21, r22)\n",
    "        argm=np.argmax(np.array([r21, r22]))\n",
    "        if argm==0:\n",
    "            victory+=1\n",
    "        elif argm==1:\n",
    "            victory1+=1\n",
    "        else:\n",
    "            victory2+=1\n",
    "print(victory, victory1, victory2)\n",
    "    \n",
    "#print('times naive won:', victory, 'times barra won', victory1)\n",
    "    \n",
    "        \n",
    "#    #check errors are independent of factors!\n",
    "#     for k in range(X.shape[1]):\n",
    "#         if k>0:\n",
    "#             print(keys[k-1])\n",
    "#         plt.scatter(range(len(X.T[k])),X.T[k])#, error)\n",
    "#         plt.show()\n",
    "\n",
    "####check that errors are more or less iid by plotting covariance matrix####\n",
    "\n",
    "rsquares=np.array(rsquares)\n",
    "print(rsquares)\n",
    "print(np.min(rsquares), np.max(rsquares), np.mean(rsquares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 in memory is factor loadings at final time - we can use that\n",
    "import statsmodels\n",
    "predictions=np.array(predictions)\n",
    "errors=np.array(errors)\n",
    "ret=np.array(ret)\n",
    "factor_loadings=np.array(factor_loadings)\n",
    "factor_cov=np.cov(factor_loadings.T)\n",
    "#factor_cov.shape\n",
    "est_covariance=np.dot( np.dot(X2, np.cov(factor_loadings.T)), X2.T) \n",
    "delta=np.var(errors, axis=0)\n",
    "est_covariance+=np.diag(delta)\n",
    "raw_corr=np.corrcoef(ret.T)\n",
    "raw_est_corr=np.corrcoef(predictions.T)\n",
    "est_corr=statsmodels.stats.moment_helpers.cov2corr(est_covariance)\n",
    "print('first plots Corr(raw_returns), second plots Corr(predicted_returns), \\\n",
    "third plots Factors.Corr(beta).Factors^T + Diag(err^2) ')\n",
    "#print(raw_corr.shape, raw_est_corr.shape, est_corr.shape)\n",
    "#heatmap of raw correlation\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(raw_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "#ZZZ.figure.savefig(\"raw_corr.png\")\n",
    "#heatmap of raw correlation\n",
    "\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(raw_est_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "#ZZZ.figure.savefig(\"raw_estimated_corr.png\")\n",
    "#heatmap of estimated correlation\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(est_corr[:15,:15], annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "#ZZZ.figure.savefig(\"model_corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_difference=est_corr-raw_corr\n",
    "corr_difference\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ZZZ=sns.heatmap(corr_difference[:15,:15], vmin=-0.00001, vmax=0.00001, annot = True, linewidths=1.5, ax=ax,xticklabels=coins[:15], yticklabels=coins[:15])\n",
    "ax.set_title('model_estimated_correlations - raw_correlations')\n",
    "ZZZ.figure.savefig(\"correlation_difference.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_tomorrow=ret[1:]\n",
    "ret_today=ret[:-1]\n",
    "err_tomorrow=errors[1:]\n",
    "err_today=errors[:-1]\n",
    "serial_ret_corr=np.corrcoef(ret_tomorrow.T , ret_today.T)[:32,32:].diagonal()\n",
    "serial_error_corr=np.corrcoef(err_tomorrow.T , err_today.T)[:32,32:].diagonal()\n",
    "ser_ret_m=np.mean(serial_ret_corr)\n",
    "ser_ret_std=np.std(serial_ret_corr)\n",
    "ser_err_m=np.mean(serial_error_corr)\n",
    "ser_err_std=np.std(serial_error_corr)\n",
    "print('mean and std for serial return correlations')\n",
    "print(ser_ret_m, ser_ret_std)\n",
    "print('mean and std for serial residual correlations')\n",
    "print(ser_err_m, ser_err_std)\n",
    "#plt.xlim(-1e-3,1e-3)\n",
    "#plt.ylim(-1e-3,1e-3)\n",
    "plt.ylabel('serial error corr')\n",
    "plt.xlabel('serial return corr')\n",
    "plt.xticks(rotation=90)\n",
    "plt.scatter(serial_ret_corr,serial_error_corr)\n",
    "# plt.savefig(\"serial_correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above.\n",
    "ser_corr_ret=[]\n",
    "ser_corr_err=[]\n",
    "for c in range(32):\n",
    "    ser_corr_ret.append(np.corrcoef(ret.T[c][1:], ret.T[c][:-1])[0,1])\n",
    "    ser_corr_err.append(np.corrcoef(errors.T[c][1:], errors.T[c][:-1])[0,1])\n",
    "ser_corr_ret=np.array(ser_corr_ret)\n",
    "plt.scatter(ser_corr_ret, ser_corr_err)\n",
    "plt.savefig(\"serial.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.odr\n",
    "def f(B,x):\n",
    "    return B[0]*x + B[1]\n",
    "linear=scipy.odr.Model(f)\n",
    "data=scipy.odr.Data(serial_ret_corr,serial_error_corr)#order is x,y for data.\n",
    "odr = scipy.odr.ODR(data, linear, beta0=[0, 0])\n",
    "out=odr.run()\n",
    "out.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in range(32):\n",
    "    Y=ret.T[c].T\n",
    "    Y_=Y[7:]\n",
    "    matrix_c=np.append(Y[:7], np.zeros(133))\n",
    "    for t in range(1,133):\n",
    "        row=np.append(np.append(np.zeros(t), Y[t:t+7]), np.zeros(133-t))\n",
    "        matrix_c=np.vstack((matrix_c, row.T))\n",
    "#     print(Y_)\n",
    "#     for j in range(133):\n",
    "#         print(matrix_c[j])\n",
    "    ols=sm.OLS(Y_, X).fit()\n",
    "    print(ols.params)\n",
    "    print(ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoregressive model for returns, weekly.\n",
    "#R_t = linear function in (R_{t-1},...,R_{t-7})\n",
    "for t in range(ret.shape[0]-7):\n",
    "    Y=ret[t+7]\n",
    "    X=ret[t:t+7].T\n",
    "    ar7=sm.OLS(Y,X).fit()\n",
    "    #print(ar7.rsquared)\n",
    "import statsmodels.tsa.ar_model as AR\n",
    "for t in range(32):\n",
    "    lag=7\n",
    "    Y=ret.T[t]\n",
    "    ar=AR.AR(Y).fit(maxlag=lag)\n",
    "    Y_hat=ar.predict()\n",
    "    RES=Y[lag:]-Y_hat\n",
    "    TSS=np.sum((Y-np.mean(Y))**2)\n",
    "    RSS=np.sum((RES-np.mean(RES))**2)\n",
    "    R2=1-RSS/TSS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
